{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Anomaly Detection in Credit Card transactions with different classification algorithms.\n",
    " \n",
    "Dataset: Credit Card Fraud Detection https://www.kaggle.com/mlg-ulb/creditcardfraud/data\n",
    "\n",
    "This dataset presents transactions that occurred in two days, where we got 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot find the original features and more background information about the data. Features V1, V2, ... V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n",
    "\n",
    " #### The implementation is done using the DataFrame-based API of SparkMLlib.\n",
    " \n",
    " #### Algorithms:\n",
    " \n",
    "   - GBTClassifier\n",
    "   - RandomForestClassifier\n",
    "   - DecisionTreeClassifier\n",
    "   - MultilayerPerceptronClassifier\n",
    "   - NaiveBayes\n",
    "   - LinearSVC\n",
    "   - LogisticRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>573</td><td>application_1580996944851_0529</td><td>spark</td><td>idle</td><td><a target=\"_blank\" href=\"http://spark-master.local:8088/proxy/application_1580996944851_0529/\">Link</a></td><td><a target=\"_blank\" href=\"http://spark-worker03.local:8042/node/containerlogs/container_1580996944851_0529_01_000001/sparkuser\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import org.apache.spark._\n",
      "import org.apache.spark.sql._\n",
      "import org.apache.spark.rdd.RDD\n",
      "import org.apache.spark.sql.functions._\n",
      "import org.apache.spark.sql.{DataFrame, Row, SparkSession}\n",
      "import org.apache.spark.sql.functions.col\n",
      "import org.apache.spark.ml.feature.{StandardScaler, VectorAssembler, StringIndexer, MinMaxScaler}\n",
      "import org.apache.spark.ml.Pipeline\n",
      "import org.apache.spark.ml.classification.{GBTClassifier, RandomForestClassifier, DecisionTreeClassifier, MultilayerPerceptronClassifier, NaiveBayes, LinearSVC, LogisticRegression, OneVsRest}\n",
      "import org.apache.spark.ml.evaluation.{MulticlassClassificationEvaluator, BinaryClassificationEvaluator}\n",
      "import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\n",
      "import org.apache.spark.mllib.linalg.Vectors\n",
      "import java.io.{File, PrintWriter}\n",
      "import java.text.SimpleDateFormat\n",
      "import java.util.Calendar\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark._\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.rdd.RDD\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.{DataFrame, Row, SparkSession}\n",
    "import org.apache.spark.sql.functions.{col}\n",
    "import org.apache.spark.ml.feature.{StandardScaler, VectorAssembler, StringIndexer, MinMaxScaler}\n",
    "import org.apache.spark.ml.{Pipeline}\n",
    "import org.apache.spark.ml.classification.{GBTClassifier, RandomForestClassifier, DecisionTreeClassifier, MultilayerPerceptronClassifier, NaiveBayes, LinearSVC, LogisticRegression, OneVsRest}\n",
    "import org.apache.spark.ml.evaluation.{MulticlassClassificationEvaluator,BinaryClassificationEvaluator}\n",
    "import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\n",
    "import org.apache.spark.mllib.linalg.Vectors\n",
    "import java.io.{File, PrintWriter}\n",
    "import java.text.SimpleDateFormat\n",
    "import java.util.Calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw: org.apache.spark.sql.DataFrame = [Time: string, V1: string ... 29 more fields]\n"
     ]
    }
   ],
   "source": [
    "val raw = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"mode\", \"DROPMALFORMED\").csv(\"datasets/creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df: org.apache.spark.sql.DataFrame = [V1: double, V2: double ... 29 more fields]\n"
     ]
    }
   ],
   "source": [
    "// cast all the column to Double type.\n",
    "val df = raw.select(((1 to 28).map(i => \"V\" + i) ++ Array(\"Time\", \"Amount\", \"Class\")).map(s => col(s).cast(\"Double\")): _*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of records: 284807\n"
     ]
    }
   ],
   "source": [
    "println(\"num of records: \" + df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------+----+------+-----+\n",
      "|                V1|                 V2|Time|Amount|Class|\n",
      "+------------------+-------------------+----+------+-----+\n",
      "|  -1.3598071336738|-0.0727811733098497| 0.0|149.62|  0.0|\n",
      "|  1.19185711131486|   0.26615071205963| 0.0|  2.69|  0.0|\n",
      "| -1.35835406159823|  -1.34016307473609| 1.0|378.66|  0.0|\n",
      "|-0.966271711572087| -0.185226008082898| 1.0| 123.5|  0.0|\n",
      "| -1.15823309349523|  0.877736754848451| 2.0| 69.99|  0.0|\n",
      "|-0.425965884412454|  0.960523044882985| 2.0|  3.67|  0.0|\n",
      "|  1.22965763450793|  0.141003507049326| 4.0|  4.99|  0.0|\n",
      "|-0.644269442348146|   1.41796354547385| 7.0|  40.8|  0.0|\n",
      "| -0.89428608220282|  0.286157196276544| 7.0|  93.2|  0.0|\n",
      "| -0.33826175242575|   1.11959337641566| 9.0|  3.68|  0.0|\n",
      "|  1.44904378114715|  -1.17633882535966|10.0|   7.8|  0.0|\n",
      "|  0.38497821518095|  0.616109459176472|10.0|  9.99|  0.0|\n",
      "|    1.249998742053|  -1.22163680921816|10.0| 121.5|  0.0|\n",
      "|   1.0693735878819|  0.287722129331455|11.0|  27.5|  0.0|\n",
      "|  -2.7918547659339| -0.327770756658658|12.0|  58.8|  0.0|\n",
      "|-0.752417042956605|  0.345485415344747|12.0| 15.99|  0.0|\n",
      "|  1.10321543528383|-0.0402962145973447|12.0| 12.99|  0.0|\n",
      "|-0.436905071360625|  0.918966212909322|13.0|  0.89|  0.0|\n",
      "| -5.40125766315825|  -5.45014783420644|14.0|  46.8|  0.0|\n",
      "|   1.4929359769862|  -1.02934573189487|15.0|   5.0|  0.0|\n",
      "+------------------+-------------------+----+------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      " Class statistics: 1 represents fraud and 0 represents normal\n",
      "+-----+------+\n",
      "|Class| count|\n",
      "+-----+------+\n",
      "|  0.0|284315|\n",
      "|  1.0|   492|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// select a few columns to show.\n",
    "df.select(\"V1\", \"V2\", \"Time\", \"Amount\", \"Class\").show()\n",
    "println(\" Class statistics: 1 represents fraud and 0 represents normal\")\n",
    "df.groupBy(\"Class\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: org.apache.spark.sql.DataFrame = [Time: double]\n"
     ]
    }
   ],
   "source": [
    "val time = df.select(\"Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time0: org.apache.spark.sql.DataFrame = [Time: double]\n"
     ]
    }
   ],
   "source": [
    "val time0 = df.filter($\"Class\" === \"0\").select(\"Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time1: org.apache.spark.sql.DataFrame = [Time: double]\n"
     ]
    }
   ],
   "source": [
    "val time1 = df.filter($\"Class\" === \"1\").select(\"Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|              Time|\n",
      "+-------+------------------+\n",
      "|  count|            284807|\n",
      "|   mean| 94813.85957508067|\n",
      "| stddev|47488.145954566215|\n",
      "|    min|               0.0|\n",
      "|    max|          172792.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time.describe(\"Time\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|             Time|\n",
      "+-------+-----------------+\n",
      "|  count|           284315|\n",
      "|   mean|94838.20225805884|\n",
      "| stddev|47484.01578555081|\n",
      "|    min|              0.0|\n",
      "|    max|         172792.0|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time0.describe(\"Time\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|             Time|\n",
      "+-------+-----------------+\n",
      "|  count|              492|\n",
      "|   mean|80746.80691056911|\n",
      "| stddev|47835.36513767506|\n",
      "|    min|            406.0|\n",
      "|    max|         170348.0|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time1.describe(\"Time\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 1. Build an inital pipeline for feature transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labelConverter: org.apache.spark.ml.feature.StringIndexer = strIdx_33ea464affb1\n",
      "assembler: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_799e7dc7a77f\n",
      "scaler: org.apache.spark.ml.feature.MinMaxScaler = minMaxScal_f25d535fff57\n",
      "pipeline: org.apache.spark.ml.Pipeline = pipeline_3ba1d85e5b7a\n",
      "pipelineModel: org.apache.spark.ml.PipelineModel = pipeline_3ba1d85e5b7a\n",
      "data: org.apache.spark.sql.DataFrame = [V1: double, V2: double ... 32 more fields]\n",
      "Generate feature from raw data:\n",
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[0.93519233743373...|  0.0|\n",
      "|[0.97854195497169...|  0.0|\n",
      "|[0.93521702332994...|  0.0|\n",
      "|[0.94187801720890...|  0.0|\n",
      "|[0.93861683090479...|  0.0|\n",
      "|[0.95105714452038...|  0.0|\n",
      "|[0.97918413907815...|  0.0|\n",
      "|[0.94734843724736...|  0.0|\n",
      "|[0.94310096396120...|  0.0|\n",
      "|[0.95254712917866...|  0.0|\n",
      "|[0.98291123819341...|  0.0|\n",
      "|[0.96483408113384...|  0.0|\n",
      "|[0.97952970932083...|  0.0|\n",
      "|[0.97646111149632...|  0.0|\n",
      "|[0.91086362048888...|  0.0|\n",
      "|[0.94551114335839...|  0.0|\n",
      "|[0.97703604260041...|  0.0|\n",
      "|[0.95087130127266...|  0.0|\n",
      "|[0.86653309470779...|  0.0|\n",
      "|[0.98365691227897...|  0.0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// convert the label from {0, 1} to {1, 2}\n",
    "//val labelConverter = new FuncTransformer(udf {d: Double => if (d==0) 2 else d }).setInputCol(\"Class\").setOutputCol(\"Class\")\n",
    "val labelConverter = new StringIndexer().setInputCol(\"Class\").setOutputCol(\"label\")\n",
    "val assembler = new VectorAssembler().setInputCols((1 to 28).map(i => \"V\" + i).toArray ++ Array(\"Amount\")).setOutputCol(\"assembled\")\n",
    "val scaler = new MinMaxScaler().setInputCol(\"assembled\").setOutputCol(\"features\")\n",
    "//val scaler = new StandardScaler().setInputCol(\"assembled\").setOutputCol(\"features\")\n",
    "val pipeline = new Pipeline().setStages(Array(assembler, scaler, labelConverter))\n",
    "val pipelineModel = pipeline.fit(df)\n",
    "val data = pipelineModel.transform(df)\n",
    "println(\"Generate feature from raw data:\")\n",
    "data.select(\"features\", \"label\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.createOrReplaceTempView(\"creditcard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "//%%sql --maxrows 3\n",
    "//SELECT count(v1),Time FROM creditcard GROUP BY Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 2. split the dataset into training and validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitTime: Double = 132929.0\n",
      "trainingData: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [V1: double, V2: double ... 32 more fields]\n",
      "validationData: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [V1: double, V2: double ... 32 more fields]\n",
      "Split data into Training and Validation: \n",
      "training records count: 199364\n",
      "validation records count: 85443\n"
     ]
    }
   ],
   "source": [
    "    val splitTime = data.stat.approxQuantile(\"Time\", Array(0.7), 0.0).head\n",
    "    val trainingData = data.filter(s\"Time<$splitTime\").cache()\n",
    "    val validationData = data.filter(s\"Time>=$splitTime\").cache()\n",
    "    println(\"Split data into Training and Validation: \")\n",
    "    println(\"training records count: \" + trainingData.count())\n",
    "    println(\"validation records count: \" + validationData.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training set statistics: 1 represents fraud and 0 represents normal\n",
      "+-----+------+\n",
      "|Class| count|\n",
      "+-----+------+\n",
      "|  0.0|198980|\n",
      "|  1.0|   384|\n",
      "+-----+------+\n",
      "\n",
      " Validation set statistics: 1 represents fraud and 0 represents normal\n",
      "+-----+-----+\n",
      "|Class|count|\n",
      "+-----+-----+\n",
      "|  0.0|85335|\n",
      "|  1.0|  108|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(\" Training set statistics: 1 represents fraud and 0 represents normal\")\n",
    "trainingData.groupBy(\"Class\").count().show()\n",
    "println(\" Validation set statistics: 1 represents fraud and 0 represents normal\")\n",
    "validationData.groupBy(\"Class\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training random forest numTrees : 10, impurity : entropy, maxBins: 24, maxDepth : 4\n",
      "Area Under ROC Curve = 0.8055496962949943\n",
      "Training random forest numTrees : 10, impurity : entropy, maxBins: 24, maxDepth : 6\n",
      "Area Under ROC Curve = 0.8518284148096066\n",
      "Training random forest numTrees : 10, impurity : entropy, maxBins: 24, maxDepth : 8\n",
      "Area Under ROC Curve = 0.8518284148096066\n",
      "Training random forest numTrees : 10, impurity : entropy, maxBins: 28, maxDepth : 4\n",
      "Area Under ROC Curve = 0.8009200666653646\n",
      "Training random forest numTrees : 10, impurity : entropy, maxBins: 28, maxDepth : 6\n",
      "Area Under ROC Curve = 0.8564580444392361\n",
      "Training random forest numTrees : 10, impurity : entropy, maxBins: 28, maxDepth : 8\n",
      "Area Under ROC Curve = 0.8564521851786748\n",
      "Training random forest numTrees : 10, impurity : entropy, maxBins: 32, maxDepth : 4\n",
      "Area Under ROC Curve = 0.7777719185172165\n",
      "Training random forest numTrees : 10, impurity : entropy, maxBins: 32, maxDepth : 6\n",
      "Area Under ROC Curve = 0.8564580444392361\n",
      "Training random forest numTrees : 10, impurity : entropy, maxBins: 32, maxDepth : 8\n",
      "Area Under ROC Curve = 0.8564814814814814\n",
      "Training random forest numTrees : 10, impurity : gini, maxBins: 24, maxDepth : 4\n",
      "Area Under ROC Curve = 0.7870135999947917\n",
      "Training random forest numTrees : 10, impurity : gini, maxBins: 24, maxDepth : 6\n",
      "Area Under ROC Curve = 0.8240564962923901\n",
      "Training random forest numTrees : 10, impurity : gini, maxBins: 24, maxDepth : 8\n",
      "Area Under ROC Curve = 0.8472046444405383\n",
      "Training random forest numTrees : 10, impurity : gini, maxBins: 28, maxDepth : 4\n",
      "Area Under ROC Curve = 0.773142288887587\n",
      "Training random forest numTrees : 10, impurity : gini, maxBins: 28, maxDepth : 6\n",
      "Area Under ROC Curve = 0.8471987851799769\n",
      "Training random forest numTrees : 10, impurity : gini, maxBins: 28, maxDepth : 8\n",
      "Area Under ROC Curve = 0.8610876740688659\n",
      "Training random forest numTrees : 10, impurity : gini, maxBins: 32, maxDepth : 4\n",
      "Area Under ROC Curve = 0.7453527925886865\n",
      "Training random forest numTrees : 10, impurity : gini, maxBins: 32, maxDepth : 6\n",
      "Area Under ROC Curve = 0.8471929259194156\n",
      "Training random forest numTrees : 10, impurity : gini, maxBins: 32, maxDepth : 8\n",
      "Area Under ROC Curve = 0.8471870666588543\n",
      "Training random forest numTrees : 15, impurity : entropy, maxBins: 24, maxDepth : 4\n",
      "Area Under ROC Curve = 0.7453703703703703\n",
      "Training random forest numTrees : 15, impurity : entropy, maxBins: 24, maxDepth : 6\n",
      "Area Under ROC Curve = 0.8379571037024017\n",
      "Training random forest numTrees : 15, impurity : entropy, maxBins: 24, maxDepth : 8\n",
      "Area Under ROC Curve = 0.847216362961661\n",
      "Training random forest numTrees : 15, impurity : entropy, maxBins: 28, maxDepth : 4\n",
      "Area Under ROC Curve = 0.7731481481481481\n",
      "Training random forest numTrees : 15, impurity : entropy, maxBins: 28, maxDepth : 6\n",
      "Area Under ROC Curve = 0.8379571037024017\n",
      "Training random forest numTrees : 15, impurity : entropy, maxBins: 28, maxDepth : 8\n",
      "Area Under ROC Curve = 0.842563296289786\n",
      "Training random forest numTrees : 15, impurity : entropy, maxBins: 32, maxDepth : 4\n",
      "Area Under ROC Curve = 0.796290437035735\n",
      "Training random forest numTrees : 15, impurity : entropy, maxBins: 32, maxDepth : 6\n",
      "Area Under ROC Curve = 0.8379571037024017\n",
      "Training random forest numTrees : 15, impurity : entropy, maxBins: 32, maxDepth : 8\n",
      "Area Under ROC Curve = 0.8379512444418404\n",
      "Training random forest numTrees : 15, impurity : gini, maxBins: 24, maxDepth : 4\n",
      "Area Under ROC Curve = 0.7592592592592593\n",
      "Training random forest numTrees : 15, impurity : gini, maxBins: 24, maxDepth : 6\n",
      "Area Under ROC Curve = 0.8101793259246239\n",
      "Training random forest numTrees : 15, impurity : gini, maxBins: 24, maxDepth : 8\n",
      "Area Under ROC Curve = 0.8425808740714699\n",
      "Training random forest numTrees : 15, impurity : gini, maxBins: 28, maxDepth : 4\n",
      "Area Under ROC Curve = 0.7916666666666667\n",
      "Training random forest numTrees : 15, impurity : gini, maxBins: 28, maxDepth : 6\n",
      "Area Under ROC Curve = 0.842563296289786\n",
      "Training random forest numTrees : 15, impurity : gini, maxBins: 28, maxDepth : 8\n",
      "Area Under ROC Curve = 0.8610876740688659\n",
      "Training random forest numTrees : 15, impurity : gini, maxBins: 32, maxDepth : 4\n",
      "Area Under ROC Curve = 0.7824015481468461\n",
      "Training random forest numTrees : 15, impurity : gini, maxBins: 32, maxDepth : 6\n",
      "Area Under ROC Curve = 0.8379395259207176\n",
      "Training random forest numTrees : 15, impurity : gini, maxBins: 32, maxDepth : 8\n",
      "Area Under ROC Curve = 0.8518166962884839\n",
      "Training random forest numTrees : 20, impurity : entropy, maxBins: 24, maxDepth : 4\n",
      "Area Under ROC Curve = 0.7870311777764757\n",
      "Training random forest numTrees : 20, impurity : entropy, maxBins: 24, maxDepth : 6\n",
      "Area Under ROC Curve = 0.847216362961661\n",
      "Training random forest numTrees : 20, impurity : entropy, maxBins: 24, maxDepth : 8\n",
      "Area Under ROC Curve = 0.8564756222209201\n",
      "Training random forest numTrees : 20, impurity : entropy, maxBins: 28, maxDepth : 4\n",
      "Area Under ROC Curve = 0.7962962962962963\n",
      "Training random forest numTrees : 20, impurity : entropy, maxBins: 28, maxDepth : 6\n",
      "Area Under ROC Curve = 0.8425867333320313\n",
      "Training random forest numTrees : 20, impurity : entropy, maxBins: 28, maxDepth : 8\n",
      "Area Under ROC Curve = 0.8425808740714699\n",
      "Training random forest numTrees : 20, impurity : entropy, maxBins: 32, maxDepth : 4\n",
      "Area Under ROC Curve = 0.7731364296270254\n",
      "Training random forest numTrees : 20, impurity : entropy, maxBins: 32, maxDepth : 6\n",
      "Area Under ROC Curve = 0.851834274070168\n",
      "Training random forest numTrees : 20, impurity : entropy, maxBins: 32, maxDepth : 8\n",
      "Area Under ROC Curve = 0.8518401333307292\n",
      "Training random forest numTrees : 20, impurity : gini, maxBins: 24, maxDepth : 4\n",
      "Area Under ROC Curve = 0.7407407407407407\n",
      "Training random forest numTrees : 20, impurity : gini, maxBins: 24, maxDepth : 6\n",
      "Area Under ROC Curve = 0.828691985182581\n",
      "Training random forest numTrees : 20, impurity : gini, maxBins: 24, maxDepth : 8\n",
      "Area Under ROC Curve = 0.8611052518505499\n",
      "Training random forest numTrees : 20, impurity : gini, maxBins: 28, maxDepth : 4\n",
      "Area Under ROC Curve = 0.7361052518505499\n",
      "Training random forest numTrees : 20, impurity : gini, maxBins: 28, maxDepth : 6\n",
      "Area Under ROC Curve = 0.8379571037024017\n",
      "Training random forest numTrees : 20, impurity : gini, maxBins: 28, maxDepth : 8\n",
      "Area Under ROC Curve = 0.8518401333307292\n",
      "Training random forest numTrees : 20, impurity : gini, maxBins: 32, maxDepth : 4\n",
      "Area Under ROC Curve = 0.7638830296283275\n",
      "Training random forest numTrees : 20, impurity : gini, maxBins: 32, maxDepth : 6\n",
      "Area Under ROC Curve = 0.828691985182581\n",
      "Training random forest numTrees : 20, impurity : gini, maxBins: 32, maxDepth : 8\n",
      "Area Under ROC Curve = 0.8472105037010995\n",
      "((20,gini,24,8),RandomForestClassificationModel (uid=rfc_0ceeafa75fc8) with 20 trees,0.8611052518505499)\n",
      "((10,gini,28,8),RandomForestClassificationModel (uid=rfc_2e59a19ab768) with 10 trees,0.8610876740688659)\n",
      "((15,gini,28,8),RandomForestClassificationModel (uid=rfc_47433d92b2ba) with 15 trees,0.8610876740688659)\n",
      "((10,entropy,32,8),RandomForestClassificationModel (uid=rfc_25f43b04e023) with 10 trees,0.8564814814814814)\n",
      "((20,entropy,24,8),RandomForestClassificationModel (uid=rfc_8009994d64c8) with 20 trees,0.8564756222209201)\n",
      "rfModel: Unit = ()\n"
     ]
    }
   ],
   "source": [
    "val rfModel = {\n",
    "    val rfGridSearch = for (\n",
    "    rfNumTrees <- Array(10, 15, 20);\n",
    "    rfImpurity <- Array(\"entropy\",\"gini\");\n",
    "    rfMaxBins <- Array(24, 28, 32);\n",
    "    rfmaxDepth <- Array(4, 6, 8)) \n",
    "    yield {\n",
    "   println(s\"Training random forest numTrees : $rfNumTrees, impurity : $rfImpurity, maxBins: $rfMaxBins, maxDepth : $rfmaxDepth\")     \n",
    "   val rfModel = new RandomForestClassifier().setLabelCol(\"label\").setFeaturesCol(\"features\").setNumTrees(rfNumTrees).setImpurity(rfImpurity).setMaxDepth(rfmaxDepth).setSeed(42).setMaxBins(rfMaxBins).fit(trainingData)\n",
    "   val predictionsRF = rfModel.transform(validationData)      \n",
    "   val rfAUC = new BinaryClassificationEvaluator().setRawPredictionCol(\"prediction\").setLabelCol(\"label\").setMetricName(\"areaUnderROC\").evaluate(predictionsRF)  \n",
    "   println(\"Area Under ROC Curve = \" + rfAUC)\n",
    "        ((rfNumTrees, rfImpurity, rfMaxBins, rfmaxDepth), rfModel, rfAUC)\n",
    "    }\n",
    "    \n",
    "    println(rfGridSearch.sortBy(-_._3).take(5).mkString(\"\\n\"))\n",
    "        val BestModel = rfGridSearch.sortBy(-_._3).head._2\n",
    "}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: Long = 27741046400737793\n",
      "gbt: org.apache.spark.ml.classification.GBTClassifier = gbtc_a6910f947395\n"
     ]
    }
   ],
   "source": [
    "//Gradient-boosted tree classifier\n",
    "// Train a GBT model.\n",
    "//setImpurity(\"entropy\") \n",
    "val t = System.nanoTime\n",
    "val gbt = new GBTClassifier().setLabelCol(\"label\").setFeaturesCol(\"features\").setMaxIter(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelGBT: org.apache.spark.ml.classification.GBTClassificationModel = GBTClassificationModel (uid=gbtc_a6910f947395) with 10 trees\n",
      "durationtrain: Double = 12.650345152\n",
      "\n",
      "initial model training finished.\n",
      "Training process takes 12.650345152 secs\n"
     ]
    }
   ],
   "source": [
    "val modelGBT = gbt.fit(trainingData)\n",
    "val durationtrain = (System.nanoTime - t) / 1e9d\n",
    "println(\"\\ninitial model training finished.\")\n",
    "println(s\"Training process takes $durationtrain secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: Long = 27741060608260362\n",
      "predictionsGBT: org.apache.spark.sql.DataFrame = [V1: double, V2: double ... 35 more fields]\n",
      "durationprediction: Double = 0.230977451\n",
      "\n",
      "initial model training finished.\n",
      "Training process takes 0.230977451 secs\n",
      "res33: predictionsGBT.type = [V1: double, V2: double ... 35 more fields]\n",
      "+----------+-----+\n",
      "|prediction|label|\n",
      "+----------+-----+\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val s = System.nanoTime\n",
    "val predictionsGBT = modelGBT.transform(validationData)\n",
    "val durationprediction = (System.nanoTime - s) / 1e9d\n",
    "println(\"\\ninitial model training finished.\")\n",
    "println(s\"Training process takes $durationprediction secs\")\n",
    "predictionsGBT.cache()\n",
    "//val predictionsAndLabel: RDD[Row] = df.rdd= predictionsGBT.select(\"prediction\", \"label\")\n",
    "predictionsGBT.select(\"prediction\", \"label\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified test set :\n",
      "+-----+-----+\n",
      "|Class|count|\n",
      "+-----+-----+\n",
      "|  0.0|85335|\n",
      "|  1.0|  108|\n",
      "+-----+-----+\n",
      "\n",
      "Prediction :\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       0.0|85366|\n",
      "|       1.0|   77|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(s\"Classified test set :\")\n",
    "validationData.groupBy(\"Class\").count().show()\n",
    "println(s\"Prediction :\")\n",
    "predictionsGBT.groupBy(\"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "+----------+-----+-----+\n",
      "|prediction|label|count|\n",
      "+----------+-----+-----+\n",
      "|       0.0|  0.0|85328|\n",
      "|       1.0|  0.0|    7|\n",
      "|       0.0|  1.0|   38|\n",
      "|       1.0|  1.0|   70|\n",
      "+----------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(s\"Matrice de confusion :\")\n",
    "predictionsGBT.select(\"prediction\", \"label\").groupBy(\"prediction\", \"label\").count().orderBy(\"label\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluator1: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_ac2db7402e95\n",
      "evaluator2: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_0c68a22e4696\n",
      "evaluator3: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_ca926475a32f\n",
      "evaluator4: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_378c8fb268a6\n",
      "areaUnderROC: org.apache.spark.ml.evaluation.BinaryClassificationEvaluator = binEval_913de66f1a0d\n",
      "accuracy: Double = 0.9994733330992591\n",
      "Area Under ROC Curve = 0.8240330592501449\n",
      "Accuracy = 0.9994733330992591\n",
      "Precision = 0.999440511423835\n",
      "Recall = 0.9994733330992592\n",
      "F1 = 0.9994292547759536\n",
      "Test Error = 5.266669007408797E-4\n"
     ]
    }
   ],
   "source": [
    "val evaluator1 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"accuracy\")\n",
    "val evaluator2 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"weightedPrecision\")\n",
    "val evaluator3 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"weightedRecall\")\n",
    "val evaluator4 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"f1\")\n",
    "val areaUnderROC = new BinaryClassificationEvaluator().setRawPredictionCol(\"prediction\").setLabelCol(\"label\").setMetricName(\"areaUnderROC\")\n",
    "val accuracy = evaluator1.evaluate(predictionsGBT)\n",
    "println(\"Area Under ROC Curve = \" + areaUnderROC.evaluate(predictionsGBT))\n",
    "println(\"Accuracy = \" + evaluator1.evaluate(predictionsGBT))\n",
    "println(\"Precision = \" + evaluator2.evaluate(predictionsGBT))\n",
    "println(\"Recall = \" + evaluator3.evaluate(predictionsGBT))\n",
    "println(\"F1 = \" + evaluator4.evaluate(predictionsGBT))\n",
    "println(\"Test Error = \" + (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "//val metrics = new BinaryClassificationMetrics(predictionsAndLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf: org.apache.spark.ml.classification.RandomForestClassifier = rfc_ea807e98f914\n",
      "t: Long = 27741069986055982\n"
     ]
    }
   ],
   "source": [
    "// Random forest classifier\n",
    "// Train a RandomForest model.\n",
    "val rf = new RandomForestClassifier().setLabelCol(\"label\").setFeaturesCol(\"features\").setNumTrees(10)\n",
    "val t = System.nanoTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelRF: org.apache.spark.ml.classification.RandomForestClassificationModel = RandomForestClassificationModel (uid=rfc_ea807e98f914) with 10 trees\n",
      "durationtrain: Double = 2.454960518\n",
      "\n",
      "initial model training finished.\n",
      "Training process takes 2.454960518 secs\n"
     ]
    }
   ],
   "source": [
    "val modelRF = rf.fit(trainingData)\n",
    "val durationtrain = (System.nanoTime - t) / 1e9d\n",
    "println(\"\\ninitial model training finished.\")\n",
    "println(s\"Training process takes $durationtrain secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: Long = 27741072901014825\n",
      "predictionsRF: org.apache.spark.sql.DataFrame = [V1: double, V2: double ... 35 more fields]\n",
      "durationprediction: Double = 0.262056219\n",
      "\n",
      "initial model training finished.\n",
      "Training process takes 0.262056219 secs\n",
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       0.0|  0.0|[0.93273307306919...|\n",
      "|       0.0|  0.0|[0.99486362369262...|\n",
      "|       0.0|  0.0|[0.98906514405821...|\n",
      "|       0.0|  0.0|[0.93238877114205...|\n",
      "|       0.0|  0.0|[0.95997796495358...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val s = System.nanoTime\n",
    "val predictionsRF = modelRF.transform(validationData)\n",
    "val durationprediction = (System.nanoTime - s) / 1e9d\n",
    "println(\"\\ninitial model training finished.\")\n",
    "println(s\"Training process takes $durationprediction secs\")\n",
    "predictionsRF.select(\"prediction\", \"label\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified test set :\n",
      "+-----+-----+\n",
      "|Class|count|\n",
      "+-----+-----+\n",
      "|  0.0|85335|\n",
      "|  1.0|  108|\n",
      "+-----+-----+\n",
      "\n",
      "Prediction :\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       0.0|85367|\n",
      "|       1.0|   76|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(s\"Classified test set :\")\n",
    "validationData.groupBy(\"Class\").count().show()\n",
    "println(s\"Prediction :\")\n",
    "predictionsRF.groupBy(\"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "+----------+-----+-----+\n",
      "|prediction|label|count|\n",
      "+----------+-----+-----+\n",
      "|       0.0|  0.0|85333|\n",
      "|       1.0|  0.0|    2|\n",
      "|       0.0|  1.0|   34|\n",
      "|       1.0|  1.0|   74|\n",
      "+----------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(s\"Matrice de confusion :\")\n",
    "predictionsRF.select(\"prediction\", \"label\").groupBy(\"prediction\", \"label\").count().orderBy(\"label\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluator1: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_ddcee36a9594\n",
      "evaluator2: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_0ed014002845\n",
      "evaluator3: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_33bf5a238976\n",
      "evaluator4: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_38db9ff81d1a\n",
      "areaUnderROC: org.apache.spark.ml.evaluation.BinaryClassificationEvaluator = binEval_7881ed0c5ff0\n",
      "accuracy: Double = 0.9995786664794073\n",
      "Area Under ROC Curve = 0.8425808740714699\n",
      "Accuracy = 0.9995786664794073\n",
      "Precision = 0.9995689598879786\n",
      "Recall = 0.9995786664794073\n",
      "F1 = 0.9995420682738061\n",
      "Test Error = 4.213335205927038E-4\n"
     ]
    }
   ],
   "source": [
    "val evaluator1 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"accuracy\")\n",
    "val evaluator2 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"weightedPrecision\")\n",
    "val evaluator3 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"weightedRecall\")\n",
    "val evaluator4 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"f1\")\n",
    "val areaUnderROC = new BinaryClassificationEvaluator().setRawPredictionCol(\"prediction\").setLabelCol(\"label\").setMetricName(\"areaUnderROC\")\n",
    "val accuracy = evaluator1.evaluate(predictionsRF)\n",
    "println(\"Area Under ROC Curve = \" + areaUnderROC.evaluate(predictionsRF))\n",
    "println(\"Accuracy = \" + evaluator1.evaluate(predictionsRF))\n",
    "println(\"Precision = \" + evaluator2.evaluate(predictionsRF))\n",
    "println(\"Recall = \" + evaluator3.evaluate(predictionsRF))\n",
    "println(\"F1 = \" + evaluator4.evaluate(predictionsRF))\n",
    "println(\"Test Error = \" + (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt: org.apache.spark.ml.classification.DecisionTreeClassifier = dtc_094f93b116ff\n",
      "t: Long = 27741081011018979\n"
     ]
    }
   ],
   "source": [
    "// Decision Tree classifier\n",
    "// Train a DecisionTree model.\n",
    "val dt = new DecisionTreeClassifier().setLabelCol(\"label\").setFeaturesCol(\"features\")\n",
    "val t = System.nanoTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelDT: org.apache.spark.ml.classification.DecisionTreeClassificationModel = DecisionTreeClassificationModel (uid=dtc_094f93b116ff) of depth 5 with 31 nodes\n",
      "durationtrain: Double = 2.62227778\n",
      "\n",
      "initial model training finished.\n",
      "Training process takes 2.62227778 secs\n"
     ]
    }
   ],
   "source": [
    "val modelDT = dt.fit(trainingData)\n",
    "val durationtrain = (System.nanoTime - t) / 1e9d\n",
    "println(\"\\ninitial model training finished.\")\n",
    "println(s\"Training process takes $durationtrain secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: Long = 27741084930243090\n",
      "predictionsDT: org.apache.spark.sql.DataFrame = [V1: double, V2: double ... 35 more fields]\n",
      "durationprediction: Double = 0.217574857\n",
      "\n",
      "initial model training finished.\n",
      "Training process takes 0.217574857 secs\n",
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       0.0|  0.0|[0.93273307306919...|\n",
      "|       0.0|  0.0|[0.99486362369262...|\n",
      "|       0.0|  0.0|[0.98906514405821...|\n",
      "|       0.0|  0.0|[0.93238877114205...|\n",
      "|       0.0|  0.0|[0.95997796495358...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val s = System.nanoTime\n",
    "val predictionsDT = modelDT.transform(validationData)\n",
    "val durationprediction = (System.nanoTime - s) / 1e9d\n",
    "println(\"\\ninitial model training finished.\")\n",
    "println(s\"Training process takes $durationprediction secs\")\n",
    "predictionsDT.select(\"prediction\", \"label\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified test set :\n",
      "+-----+-----+\n",
      "|Class|count|\n",
      "+-----+-----+\n",
      "|  0.0|85335|\n",
      "|  1.0|  108|\n",
      "+-----+-----+\n",
      "\n",
      "Prediction :\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       0.0|85369|\n",
      "|       1.0|   74|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(s\"Classified test set :\")\n",
    "validationData.groupBy(\"Class\").count().show()\n",
    "println(s\"Prediction :\")\n",
    "predictionsDT.groupBy(\"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "+----------+-----+-----+\n",
      "|prediction|label|count|\n",
      "+----------+-----+-----+\n",
      "|       0.0|  0.0|85332|\n",
      "|       1.0|  0.0|    3|\n",
      "|       0.0|  1.0|   37|\n",
      "|       1.0|  1.0|   71|\n",
      "+----------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(s\"Matrice de confusion :\")\n",
    "predictionsDT.select(\"prediction\", \"label\").groupBy(\"prediction\", \"label\").count().orderBy(\"label\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluator1: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_59bb5d25ac9e\n",
      "evaluator2: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_8bf846dfe775\n",
      "evaluator3: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_1cff0bc00741\n",
      "evaluator4: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_9d7c95a604d9\n",
      "areaUnderROC: org.apache.spark.ml.evaluation.BinaryClassificationEvaluator = binEval_452790eb4860\n",
      "accuracy: Double = 0.9995318516437859\n",
      "Area Under ROC Curve = 0.8286861259220197\n",
      "Accuracy = 0.9995318516437859\n",
      "Precision = 0.9995158919706696\n",
      "Recall = 0.999531851643786\n",
      "F1 = 0.9994881701223897\n",
      "Test Error = 4.681483562141153E-4\n"
     ]
    }
   ],
   "source": [
    "val evaluator1 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"accuracy\")\n",
    "val evaluator2 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"weightedPrecision\")\n",
    "val evaluator3 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"weightedRecall\")\n",
    "val evaluator4 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"f1\")\n",
    "val areaUnderROC = new BinaryClassificationEvaluator().setRawPredictionCol(\"prediction\").setLabelCol(\"label\").setMetricName(\"areaUnderROC\")\n",
    "val accuracy = evaluator1.evaluate(predictionsDT)\n",
    "println(\"Area Under ROC Curve = \" + areaUnderROC.evaluate(predictionsDT))\n",
    "println(\"Accuracy = \" + evaluator1.evaluate(predictionsDT))\n",
    "println(\"Precision = \" + evaluator2.evaluate(predictionsDT))\n",
    "println(\"Recall = \" + evaluator3.evaluate(predictionsDT))\n",
    "println(\"F1 = \" + evaluator4.evaluate(predictionsDT))\n",
    "println(\"Test Error = \" + (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "/* val trainingData1 = trainingData.withColumn(\"label\", when(col(\"label\") === 0, -1)\n",
    "                                   .otherwise(col(\"label\"))\n",
    "                           );\n",
    "val validationData1 = validationData.withColumn(\"label\", when(col(\"label\") === 0, -1)\n",
    "                                   .otherwise(col(\"label\"))\n",
    "                           );*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm: org.apache.spark.ml.classification.LinearSVC = linearsvc_0e878a735293\n",
      "t: Long = 27741091756026105\n"
     ]
    }
   ],
   "source": [
    "// SVM classifier\n",
    "// Train a SVM model.\n",
    "val svm = new LinearSVC().setLabelCol(\"label\").setFeaturesCol(\"features\").setMaxIter(100).setRegParam(0.1) \n",
    "val t = System.nanoTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelSVM: org.apache.spark.ml.classification.LinearSVCModel = linearsvc_0e878a735293\n",
      "durationtrain: Double = 72.644895558\n",
      "\n",
      "initial model training finished.\n",
      "Training process takes 72.644895558 secs\n"
     ]
    }
   ],
   "source": [
    "val modelSVM = svm.fit(trainingData)\n",
    "val durationtrain = (System.nanoTime - t) / 1e9d\n",
    "println(\"\\ninitial model training finished.\")\n",
    "println(s\"Training process takes $durationtrain secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: Long = 27741165310508848\n",
      "predictionsSVM: org.apache.spark.sql.DataFrame = [V1: double, V2: double ... 34 more fields]\n",
      "durationprediction: Double = 0.209437886\n",
      "\n",
      "initial model training finished.\n",
      "Training process takes 0.209437886 secs\n",
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       0.0|  0.0|[0.93273307306919...|\n",
      "|       0.0|  0.0|[0.99486362369262...|\n",
      "|       0.0|  0.0|[0.98906514405821...|\n",
      "|       0.0|  0.0|[0.93238877114205...|\n",
      "|       0.0|  0.0|[0.95997796495358...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val s = System.nanoTime\n",
    "val predictionsSVM = modelSVM.transform(validationData)\n",
    "val durationprediction = (System.nanoTime - s) / 1e9d\n",
    "println(\"\\ninitial model training finished.\")\n",
    "println(s\"Training process takes $durationprediction secs\")\n",
    "predictionsSVM.select(\"prediction\", \"label\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified test set :\n",
      "+-----+-----+\n",
      "|Class|count|\n",
      "+-----+-----+\n",
      "|  0.0|85335|\n",
      "|  1.0|  108|\n",
      "+-----+-----+\n",
      "\n",
      "Prediction :\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       0.0|85443|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(s\"Classified test set :\")\n",
    "validationData.groupBy(\"Class\").count().show()\n",
    "println(s\"Prediction :\")\n",
    "predictionsSVM.groupBy(\"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "+----------+-----+-----+\n",
      "|prediction|label|count|\n",
      "+----------+-----+-----+\n",
      "|       0.0|  0.0|85335|\n",
      "|       0.0|  1.0|  108|\n",
      "+----------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(s\"Matrice de confusion :\")\n",
    "predictionsSVM.select(\"prediction\", \"label\").groupBy(\"prediction\", \"label\").count().orderBy(\"label\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluator1: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_5921ade73f0a\n",
      "evaluator2: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_148eb487f040\n",
      "evaluator3: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_63f482a17ebe\n",
      "evaluator4: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_814d4afcf9f7\n",
      "areaUnderROC: org.apache.spark.ml.evaluation.BinaryClassificationEvaluator = binEval_ff882b57b6cf\n",
      "accuracy: Double = 0.998735999438222\n",
      "Area Under ROC Curve = 0.5\n",
      "Accuracy = 0.998735999438222\n",
      "Precision = 0.9974735965738643\n",
      "Recall = 0.998735999438222\n",
      "F1 = 0.998104398834284\n",
      "Test Error = 0.0012640005617780004\n"
     ]
    }
   ],
   "source": [
    "val evaluator1 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"accuracy\")\n",
    "val evaluator2 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"weightedPrecision\")\n",
    "val evaluator3 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"weightedRecall\")\n",
    "val evaluator4 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"f1\")\n",
    "val areaUnderROC = new BinaryClassificationEvaluator().setRawPredictionCol(\"prediction\").setLabelCol(\"label\").setMetricName(\"areaUnderROC\")\n",
    "val accuracy = evaluator1.evaluate(predictionsSVM)\n",
    "println(\"Area Under ROC Curve = \" + areaUnderROC.evaluate(predictionsSVM))\n",
    "println(\"Accuracy = \" + evaluator1.evaluate(predictionsSVM))\n",
    "println(\"Precision = \" + evaluator2.evaluate(predictionsSVM))\n",
    "println(\"Recall = \" + evaluator3.evaluate(predictionsSVM))\n",
    "println(\"F1 = \" + evaluator4.evaluate(predictionsSVM))\n",
    "println(\"Test Error = \" + (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: org.apache.spark.ml.classification.LogisticRegression = logreg_836fb4e1deba\n",
      "t: Long = 27741171985836812\n"
     ]
    }
   ],
   "source": [
    "// Logistic Regression classifier\n",
    "val lr = new LogisticRegression().setLabelCol(\"label\").setFeaturesCol(\"features\").setMaxIter(10).setTol(1E-6).setFitIntercept(true).setRegParam(0.3).setElasticNetParam(0.8)\n",
    "val t = System.nanoTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modellr: org.apache.spark.ml.classification.LogisticRegressionModel = LogisticRegressionModel: uid = logreg_836fb4e1deba, numClasses = 2, numFeatures = 29\n",
      "durationtrain: Double = 1.237882838\n",
      "\n",
      "initial model training finished.\n",
      "Training process takes 1.237882838 secs\n"
     ]
    }
   ],
   "source": [
    "// train the multiclass model.\n",
    "//val Modelovr = ovr.fit(trainingData)\n",
    "val Modellr = lr.fit(trainingData)\n",
    "val durationtrain = (System.nanoTime - t) / 1e9d\n",
    "println(\"\\ninitial model training finished.\")\n",
    "println(s\"Training process takes $durationtrain secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: Long = 27741173827800361\n",
      "predictionsLR: org.apache.spark.sql.DataFrame = [V1: double, V2: double ... 35 more fields]\n",
      "durationprediction: Double = 0.211721649\n",
      "\n",
      "initial model training finished.\n",
      "Training process takes 0.211721649 secs\n",
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       0.0|  0.0|[0.93273307306919...|\n",
      "|       0.0|  0.0|[0.99486362369262...|\n",
      "|       0.0|  0.0|[0.98906514405821...|\n",
      "|       0.0|  0.0|[0.93238877114205...|\n",
      "|       0.0|  0.0|[0.95997796495358...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val s = System.nanoTime\n",
    "val predictionsLR = Modellr.transform(validationData)\n",
    "val durationprediction = (System.nanoTime - s) / 1e9d\n",
    "println(\"\\ninitial model training finished.\")\n",
    "println(s\"Training process takes $durationprediction secs\")\n",
    "predictionsLR.select(\"prediction\", \"label\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified test set :\n",
      "+-----+-----+\n",
      "|Class|count|\n",
      "+-----+-----+\n",
      "|  0.0|85335|\n",
      "|  1.0|  108|\n",
      "+-----+-----+\n",
      "\n",
      "Prediction :\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       0.0|85443|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(s\"Classified test set :\")\n",
    "validationData.groupBy(\"Class\").count().show()\n",
    "println(s\"Prediction :\")\n",
    "predictionsLR.groupBy(\"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "+----------+-----+-----+\n",
      "|prediction|label|count|\n",
      "+----------+-----+-----+\n",
      "|       0.0|  0.0|85335|\n",
      "|       0.0|  1.0|  108|\n",
      "+----------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(s\"Matrice de confusion :\")\n",
    "predictionsLR.select(\"prediction\", \"label\").groupBy(\"prediction\", \"label\").count().orderBy(\"label\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluator1: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_887c612e2ed6\n",
      "evaluator2: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_ca567f8fca05\n",
      "evaluator3: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_cd447952483f\n",
      "evaluator4: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_b5e085d87701\n",
      "areaUnderROC: org.apache.spark.ml.evaluation.BinaryClassificationEvaluator = binEval_ea6b8f82996e\n",
      "accuracy: Double = 0.998735999438222\n",
      "Area Under ROC Curve = 0.5\n",
      "Accuracy = 0.998735999438222\n",
      "Precision = 0.9974735965738643\n",
      "Recall = 0.998735999438222\n",
      "F1 = 0.998104398834284\n",
      "Test Error = 0.0012640005617780004\n"
     ]
    }
   ],
   "source": [
    "val evaluator1 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"accuracy\")\n",
    "val evaluator2 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"weightedPrecision\")\n",
    "val evaluator3 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"weightedRecall\")\n",
    "val evaluator4 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"f1\")\n",
    "val areaUnderROC = new BinaryClassificationEvaluator().setRawPredictionCol(\"prediction\").setLabelCol(\"label\").setMetricName(\"areaUnderROC\")\n",
    "val accuracy = evaluator1.evaluate(predictionsLR)\n",
    "println(\"Area Under ROC Curve = \" + areaUnderROC.evaluate(predictionsLR))\n",
    "println(\"Accuracy = \" + evaluator1.evaluate(predictionsLR))\n",
    "println(\"Precision = \" + evaluator2.evaluate(predictionsLR))\n",
    "println(\"Recall = \" + evaluator3.evaluate(predictionsLR))\n",
    "println(\"F1 = \" + evaluator4.evaluate(predictionsLR))\n",
    "println(\"Test Error = \" + (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb: org.apache.spark.ml.classification.NaiveBayes = nb_75107e3d9433\n",
      "t: Long = 27741181556658039\n"
     ]
    }
   ],
   "source": [
    "// Naive Bayes classifier\n",
    "// Train a NaiveBayes model.\n",
    "val nb = new NaiveBayes().setLabelCol(\"label\").setFeaturesCol(\"features\").setSmoothing(1.0)\n",
    "val t = System.nanoTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "/*val scaler = new MinMaxScaler().setInputCol(\"features\").setOutputCol(\"featuresScaled\")\n",
    "val pipeline = new Pipeline().setStages(Array(scaler))\n",
    "val pipelineModel1 = pipeline.fit(trainingData)\n",
    "val pipelineModel2 = pipeline.fit(trainingData)\n",
    "val datatrain = pipelineModel1.transform(trainingData)\n",
    "val datatest = pipelineModel2.transform(validationData)*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelNB: org.apache.spark.ml.classification.NaiveBayesModel = NaiveBayesModel (uid=nb_75107e3d9433) with 2 classes\n",
      "durationtrain: Double = 1.282913141\n",
      "\n",
      "initial model training finished.\n",
      "Training process takes 1.282913141 secs\n"
     ]
    }
   ],
   "source": [
    "val modelNB = nb.fit(trainingData)\n",
    "val durationtrain = (System.nanoTime - t) / 1e9d\n",
    "println(\"\\ninitial model training finished.\")\n",
    "println(s\"Training process takes $durationtrain secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: Long = 27741183654202391\n",
      "predictionsNB: org.apache.spark.sql.DataFrame = [V1: double, V2: double ... 35 more fields]\n",
      "durationprediction: Double = 0.227650635\n",
      "\n",
      "initial model training finished.\n",
      "Training process takes 0.227650635 secs\n",
      "+----------+-----+\n",
      "|prediction|label|\n",
      "+----------+-----+\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val s = System.nanoTime\n",
    "val predictionsNB = modelNB.transform(validationData)\n",
    "val durationprediction = (System.nanoTime - s) / 1e9d\n",
    "println(\"\\ninitial model training finished.\")\n",
    "println(s\"Training process takes $durationprediction secs\")\n",
    "predictionsNB.select(\"prediction\", \"label\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified test set :\n",
      "+-----+-----+\n",
      "|Class|count|\n",
      "+-----+-----+\n",
      "|  0.0|85335|\n",
      "|  1.0|  108|\n",
      "+-----+-----+\n",
      "\n",
      "Prediction :\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       0.0|85443|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(s\"Classified test set :\")\n",
    "validationData.groupBy(\"Class\").count().show()\n",
    "println(s\"Prediction :\")\n",
    "predictionsNB.groupBy(\"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "+----------+-----+-----+\n",
      "|prediction|label|count|\n",
      "+----------+-----+-----+\n",
      "|       0.0|  0.0|85335|\n",
      "|       0.0|  1.0|  108|\n",
      "+----------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(s\"Matrice de confusion :\")\n",
    "predictionsNB.select(\"prediction\", \"label\").groupBy(\"prediction\", \"label\").count().orderBy(\"label\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluator1: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_2c2d1eed1136\n",
      "evaluator2: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_04d0077b48ea\n",
      "evaluator3: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_a537dd92569d\n",
      "evaluator4: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_45f871497299\n",
      "areaUnderROC: org.apache.spark.ml.evaluation.BinaryClassificationEvaluator = binEval_22dbbdc9413c\n",
      "accuracy: Double = 0.998735999438222\n",
      "Area Under ROC Curve = 0.5\n",
      "Accuracy = 0.998735999438222\n",
      "Precision = 0.9974735965738643\n",
      "Recall = 0.998735999438222\n",
      "F1 = 0.998104398834284\n",
      "Test Error = 0.0012640005617780004\n"
     ]
    }
   ],
   "source": [
    "val evaluator1 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"accuracy\")\n",
    "val evaluator2 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"weightedPrecision\")\n",
    "val evaluator3 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"weightedRecall\")\n",
    "val evaluator4 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"f1\")\n",
    "val areaUnderROC = new BinaryClassificationEvaluator().setRawPredictionCol(\"prediction\").setLabelCol(\"label\").setMetricName(\"areaUnderROC\")\n",
    "val accuracy = evaluator1.evaluate(predictionsNB)\n",
    "println(\"Area Under ROC Curve = \" + areaUnderROC.evaluate(predictionsNB))\n",
    "println(\"Accuracy = \" + evaluator1.evaluate(predictionsNB))\n",
    "println(\"Precision = \" + evaluator2.evaluate(predictionsNB))\n",
    "println(\"Recall = \" + evaluator3.evaluate(predictionsNB))\n",
    "println(\"F1 = \" + evaluator4.evaluate(predictionsNB))\n",
    "println(\"Test Error = \" + (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: Long = 27741190143350460\n",
      "layers: Array[Int] = Array(29, 15, 7, 2)\n",
      "mlp: org.apache.spark.ml.classification.MultilayerPerceptronClassifier = mlpc_3992e9abc817\n"
     ]
    }
   ],
   "source": [
    "// Multilayer Perceptron Classifier\n",
    "// create the trainer and set its parameters\n",
    "val t = System.nanoTime\n",
    "val layers = Array[Int] (29,15,7, 2)\n",
    "val mlp = new MultilayerPerceptronClassifier().setLayers(layers).setLabelCol(\"label\").setFeaturesCol(\"features\").setTol(1E-4).setBlockSize(128).setSeed(1234L).setMaxIter(25) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelMLP: org.apache.spark.ml.classification.MultilayerPerceptronClassificationModel = mlpc_3992e9abc817\n",
      "durationtrain: Double = 9.314514534\n",
      "\n",
      "initial model training finished.\n",
      "Training process takes 9.314514534 secs\n"
     ]
    }
   ],
   "source": [
    "// Train a Multilayer Perceptron model.\n",
    "val modelMLP = mlp.fit(trainingData)\n",
    "val durationtrain = (System.nanoTime - t) / 1e9d\n",
    "println(\"\\ninitial model training finished.\")\n",
    "println(s\"Training process takes $durationtrain secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: Long = 27741200267015758\n",
      "predictionsMLP: org.apache.spark.sql.DataFrame = [V1: double, V2: double ... 35 more fields]\n",
      "durationprediction: Double = 0.211891287\n",
      "\n",
      "initial model training finished.\n",
      "Training process takes 0.211891287 secs\n",
      "+----------+-----+\n",
      "|prediction|label|\n",
      "+----------+-----+\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val s = System.nanoTime\n",
    "val predictionsMLP = modelMLP.transform(validationData)\n",
    "val durationprediction = (System.nanoTime - s) / 1e9d\n",
    "println(\"\\ninitial model training finished.\")\n",
    "println(s\"Training process takes $durationprediction secs\")\n",
    "predictionsMLP.select(\"prediction\",\"label\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified test set :\n",
      "+-----+-----+\n",
      "|Class|count|\n",
      "+-----+-----+\n",
      "|  0.0|85335|\n",
      "|  1.0|  108|\n",
      "+-----+-----+\n",
      "\n",
      "Prediction :\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       0.0|85365|\n",
      "|       1.0|   78|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(s\"Classified test set :\")\n",
    "validationData.groupBy(\"Class\").count().show()\n",
    "println(s\"Prediction :\")\n",
    "predictionsMLP.groupBy(\"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "+----------+-----+-----+\n",
      "|prediction|label|count|\n",
      "+----------+-----+-----+\n",
      "|       0.0|  0.0|85333|\n",
      "|       1.0|  0.0|    2|\n",
      "|       0.0|  1.0|   32|\n",
      "|       1.0|  1.0|   76|\n",
      "+----------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(s\"Matrice de confusion :\")\n",
    "predictionsMLP.select(\"prediction\", \"label\").groupBy(\"prediction\", \"label\").count().orderBy(\"label\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluator1: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_33ca3a3e3a16\n",
      "evaluator2: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_bc71c8ee2c79\n",
      "evaluator3: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_2f685d0415c1\n",
      "evaluator4: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_a86f09c6fd57\n",
      "areaUnderROC: org.apache.spark.ml.evaluation.BinaryClassificationEvaluator = binEval_c1acb93ff895\n",
      "accuracy: Double = 0.999602073897218\n",
      "Area Under ROC Curve = 0.8518401333307292\n",
      "Accuracy = 0.999602073897218\n",
      "Precision = 0.9995932026620965\n",
      "Recall = 0.999602073897218\n",
      "F1 = 0.9995700180496218\n",
      "Test Error = 3.97926102781998E-4\n"
     ]
    }
   ],
   "source": [
    "val evaluator1 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"accuracy\")\n",
    "val evaluator2 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"weightedPrecision\")\n",
    "val evaluator3 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"weightedRecall\")\n",
    "val evaluator4 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"f1\")\n",
    "val areaUnderROC = new BinaryClassificationEvaluator().setRawPredictionCol(\"prediction\").setLabelCol(\"label\").setMetricName(\"areaUnderROC\")\n",
    "val accuracy = evaluator1.evaluate(predictionsMLP)\n",
    "println(\"Area Under ROC Curve = \" + areaUnderROC.evaluate(predictionsMLP))\n",
    "println(\"Accuracy = \" + evaluator1.evaluate(predictionsMLP))\n",
    "println(\"Precision = \" + evaluator2.evaluate(predictionsMLP))\n",
    "println(\"Recall = \" + evaluator3.evaluate(predictionsMLP))\n",
    "println(\"F1 = \" + evaluator4.evaluate(predictionsMLP))\n",
    "println(\"Test Error = \" + (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier: org.apache.spark.ml.classification.LogisticRegression = logreg_2c8221f7f537\n",
      "t: Long = 27741207896263766\n"
     ]
    }
   ],
   "source": [
    "// One Vs Rest Classifier using Logistic Regression classifier\n",
    "val classifier = new LogisticRegression().setLabelCol(\"label\").setFeaturesCol(\"features\").setMaxIter(10).setTol(1E-6).setFitIntercept(true) \n",
    "val t = System.nanoTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ovr: org.apache.spark.ml.classification.OneVsRest = oneVsRest_2bca44fa1d40\n",
      "Modelovr: org.apache.spark.ml.classification.OneVsRestModel = oneVsRest_2bca44fa1d40\n",
      "durationtrain: Double = 3.89588108\n",
      "\n",
      "initial model training finished.\n",
      "Training process takes 3.89588108 secs\n"
     ]
    }
   ],
   "source": [
    "// train the multiclass model.\n",
    "val ovr = new OneVsRest().setClassifier(classifier)\n",
    "val Modelovr = ovr.fit(trainingData)\n",
    "val durationtrain = (System.nanoTime - t) / 1e9d\n",
    "println(\"\\ninitial model training finished.\")\n",
    "println(s\"Training process takes $durationtrain secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: Long = 27741213899572675\n",
      "predictionsOVR: org.apache.spark.sql.DataFrame = [V1: double, V2: double ... 34 more fields]\n",
      "durationprediction: Double = 0.362011561\n",
      "\n",
      "initial model training finished.\n",
      "Training process takes 0.362011561 secs\n",
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       0.0|  0.0|[0.93273307306919...|\n",
      "|       0.0|  0.0|[0.99486362369262...|\n",
      "|       0.0|  0.0|[0.98906514405821...|\n",
      "|       0.0|  0.0|[0.93238877114205...|\n",
      "|       0.0|  0.0|[0.95997796495358...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val s = System.nanoTime\n",
    "val predictionsOVR = Modelovr.transform(validationData)\n",
    "val durationprediction = (System.nanoTime - s) / 1e9d\n",
    "println(\"\\ninitial model training finished.\")\n",
    "println(s\"Training process takes $durationprediction secs\")\n",
    "predictionsOVR.select(\"prediction\", \"label\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified test set :\n",
      "+-----+-----+\n",
      "|Class|count|\n",
      "+-----+-----+\n",
      "|  0.0|85335|\n",
      "|  1.0|  108|\n",
      "+-----+-----+\n",
      "\n",
      "Prediction :\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       0.0|85420|\n",
      "|       1.0|   23|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(s\"Classified test set :\")\n",
    "validationData.groupBy(\"Class\").count().show()\n",
    "println(s\"Prediction :\")\n",
    "predictionsOVR.groupBy(\"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "+----------+-----+-----+\n",
      "|prediction|label|count|\n",
      "+----------+-----+-----+\n",
      "|       0.0|  0.0|85335|\n",
      "|       0.0|  1.0|   85|\n",
      "|       1.0|  1.0|   23|\n",
      "+----------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(s\"Matrice de confusion :\")\n",
    "predictionsOVR.select(\"prediction\", \"label\").groupBy(\"prediction\", \"label\").count().orderBy(\"label\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluator1: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_5e0b7baff1e4\n",
      "evaluator2: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_44d72abfb50d\n",
      "evaluator3: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_81ccf0b98c78\n",
      "evaluator4: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_359688e483f0\n",
      "areaUnderROC: org.apache.spark.ml.evaluation.BinaryClassificationEvaluator = binEval_f9f93c14aec9\n",
      "areaUnderPR: org.apache.spark.ml.evaluation.BinaryClassificationEvaluator = binEval_c8b9f2fd68ca\n",
      "accuracy: Double = 0.9990051847430451\n",
      "Area Under ROC Curve = 0.6064814814814815\n",
      "Area Under the Precision-Recall Curve = 0.606978889109959\n",
      "Accuracy = 0.9990051847430451\n",
      "Precision = 0.9990061746669134\n",
      "Recall = 0.9990051847430451\n",
      "F1 = 0.9986826869394148\n",
      "Test Error = 9.94815256954884E-4\n"
     ]
    }
   ],
   "source": [
    "val evaluator1 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"accuracy\")\n",
    "val evaluator2 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"weightedPrecision\")\n",
    "val evaluator3 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"weightedRecall\")\n",
    "val evaluator4 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"f1\")\n",
    "val areaUnderROC = new BinaryClassificationEvaluator().setRawPredictionCol(\"prediction\").setLabelCol(\"label\").setMetricName(\"areaUnderROC\")\n",
    "val areaUnderPR = new BinaryClassificationEvaluator().setRawPredictionCol(\"prediction\").setLabelCol(\"label\").setMetricName(\"areaUnderPR\")\n",
    "val accuracy = evaluator1.evaluate(predictionsOVR)\n",
    "println(\"Area Under ROC Curve = \" + areaUnderROC.evaluate(predictionsOVR))\n",
    "println(\"Area Under the Precision-Recall Curve = \"  + areaUnderPR.evaluate(predictionsOVR))\n",
    "println(\"Accuracy = \" + evaluator1.evaluate(predictionsOVR))\n",
    "println(\"Precision = \" + evaluator2.evaluate(predictionsOVR))\n",
    "println(\"Recall = \" + evaluator3.evaluate(predictionsOVR))\n",
    "println(\"F1 = \" + evaluator4.evaluate(predictionsOVR))\n",
    "println(\"Test Error = \" + (1.0 - accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark",
   "language": "",
   "name": "sparkkernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
