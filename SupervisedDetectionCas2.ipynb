{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>139</td><td>application_1580996944851_0095</td><td>spark</td><td>idle</td><td><a target=\"_blank\" href=\"http://spark-master.local:8088/proxy/application_1580996944851_0095/\">Link</a></td><td><a target=\"_blank\" href=\"http://spark-worker03.local:8042/node/containerlogs/container_1580996944851_0095_01_000001/sparkuser\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import org.apache.spark._\n",
      "import org.apache.spark.sql._\n",
      "import org.apache.spark.rdd.RDD\n",
      "import org.apache.spark.sql.functions._\n",
      "import org.apache.spark.sql.{DataFrame, Row, SparkSession}\n",
      "import org.apache.spark.sql.functions.col\n",
      "import org.apache.spark.ml.feature.{StandardScaler, VectorAssembler, StringIndexer, MinMaxScaler}\n",
      "import org.apache.spark.ml.Pipeline\n",
      "import org.apache.spark.ml.classification.{GBTClassifier, RandomForestClassifier, DecisionTreeClassifier, MultilayerPerceptronClassifier, NaiveBayes, LinearSVC, LogisticRegression, OneVsRest}\n",
      "import org.apache.spark.ml.evaluation.{MulticlassClassificationEvaluator, BinaryClassificationEvaluator}\n",
      "import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\n",
      "import org.apache.spark.mllib.linalg.Vectors\n",
      "import java.io.{File, PrintWriter}\n",
      "import java.text.SimpleDateFormat\n",
      "import java.util.Calendar\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark._\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.rdd.RDD\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.{DataFrame, Row, SparkSession}\n",
    "import org.apache.spark.sql.functions.{col}\n",
    "import org.apache.spark.ml.feature.{StandardScaler, VectorAssembler, StringIndexer, MinMaxScaler}\n",
    "import org.apache.spark.ml.{Pipeline}\n",
    "import org.apache.spark.ml.classification.{GBTClassifier, RandomForestClassifier, DecisionTreeClassifier, MultilayerPerceptronClassifier, NaiveBayes, LinearSVC, LogisticRegression, OneVsRest}\n",
    "import org.apache.spark.ml.evaluation.{MulticlassClassificationEvaluator,BinaryClassificationEvaluator}\n",
    "import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\n",
    "import org.apache.spark.mllib.linalg.Vectors\n",
    "import java.io.{File, PrintWriter}\n",
    "import java.text.SimpleDateFormat\n",
    "import java.util.Calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw: org.apache.spark.sql.DataFrame = [Time: string, V1: string ... 29 more fields]\n"
     ]
    }
   ],
   "source": [
    "val raw = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"mode\", \"DROPMALFORMED\").csv(\"datasets/creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df: org.apache.spark.sql.DataFrame = [V1: double, V2: double ... 29 more fields]\n"
     ]
    }
   ],
   "source": [
    "// cast all the column to Double type.\n",
    "val df = raw.select(((1 to 28).map(i => \"V\" + i) ++ Array(\"Time\", \"Amount\", \"Class\")).map(s => col(s).cast(\"Double\")): _*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labelConverter: org.apache.spark.ml.feature.StringIndexer = strIdx_efe9741e0182\n",
      "assembler: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_0b100ce905ba\n",
      "scaler: org.apache.spark.ml.feature.MinMaxScaler = minMaxScal_7b1483af4614\n",
      "pipeline: org.apache.spark.ml.Pipeline = pipeline_bf3bdecab0da\n",
      "pipelineModel: org.apache.spark.ml.PipelineModel = pipeline_bf3bdecab0da\n",
      "data: org.apache.spark.sql.DataFrame = [V1: double, V2: double ... 32 more fields]\n",
      "Generate feature from raw data:\n",
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[0.88136490328633...|  0.0|\n",
      "|[0.84029849039390...|  0.0|\n",
      "|[0.86814081926190...|  0.0|\n",
      "|[0.86848364774806...|  0.0|\n",
      "|[0.86425070140685...|  0.0|\n",
      "|[0.85718742663956...|  0.0|\n",
      "|[0.83819983804773...|  0.0|\n",
      "|[0.85603110871019...|  0.0|\n",
      "|[0.83545216735689...|  0.0|\n",
      "|[0.85551101187934...|  0.0|\n",
      "|[0.85324951634142...|  0.0|\n",
      "|[0.82226325870284...|  0.0|\n",
      "|[0.84406658980857...|  0.0|\n",
      "|[0.85177230541965...|  0.0|\n",
      "|[0.86586281889129...|  0.0|\n",
      "|[0.87306410273210...|  0.0|\n",
      "|[0.85937468703684...|  0.0|\n",
      "|[0.85343546827309...|  0.0|\n",
      "|[0.85797059662233...|  0.0|\n",
      "|[0.84529457208090...|  0.0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// convert the label from {0, 1} to {1, 2}\n",
    "//val labelConverter = new FuncTransformer(udf {d: Double => if (d==0) 2 else d }).setInputCol(\"Class\").setOutputCol(\"Class\")\n",
    "val labelConverter = new StringIndexer().setInputCol(\"Class\").setOutputCol(\"label\")\n",
    "val assembler = new VectorAssembler().setInputCols(Array(\"V3\", \"V4\", \"V9\", \"V10\", \"V11\", \"V12\", \"V14\", \"V16\", \"V17\", \"V18\",\"V19\")).setOutputCol(\"assembled\")\n",
    "val scaler = new MinMaxScaler().setInputCol(\"assembled\").setOutputCol(\"features\")\n",
    "//val scaler = new StandardScaler().setInputCol(\"assembled\").setOutputCol(\"features\")\n",
    "val pipeline = new Pipeline().setStages(Array(assembler, scaler, labelConverter))\n",
    "val pipelineModel = pipeline.fit(df)\n",
    "val data = pipelineModel.transform(df)\n",
    "println(\"Generate feature from raw data:\")\n",
    "data.select(\"features\", \"label\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 2. split the dataset into training and validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitTime: Double = 132970.0\n",
      "trainingData: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [V1: double, V2: double ... 32 more fields]\n",
      "validationData: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [V1: double, V2: double ... 32 more fields]\n",
      "Split data into Training and Validation: \n",
      "training records count: 199440\n",
      "validation records count: 85367\n"
     ]
    }
   ],
   "source": [
    "val splitTime = data.stat.approxQuantile(\"Time\", Array(0.7), 0.001).head\n",
    "    val trainingData = data.filter(s\"Time<$splitTime\").cache()\n",
    "    val validationData = data.filter(s\"Time>=$splitTime\").cache()\n",
    "    println(\"Split data into Training and Validation: \")\n",
    "    println(\"training records count: \" + trainingData.count())\n",
    "    println(\"validation records count: \" + validationData.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training set statistics: 1 represents fraud and 0 represents normal\n",
      "+-----+------+\n",
      "|Class| count|\n",
      "+-----+------+\n",
      "|  0.0|199056|\n",
      "|  1.0|   384|\n",
      "+-----+------+\n",
      "\n",
      " Validation set statistics: 1 represents fraud and 0 represents normal\n",
      "+-----+-----+\n",
      "|Class|count|\n",
      "+-----+-----+\n",
      "|  0.0|85259|\n",
      "|  1.0|  108|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(\" Training set statistics: 1 represents fraud and 0 represents normal\")\n",
    "trainingData.groupBy(\"Class\").count().show()\n",
    "println(\" Validation set statistics: 1 represents fraud and 0 represents normal\")\n",
    "validationData.groupBy(\"Class\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training random forest numTrees : 10, impurity : entropy, maxBins: 24, maxDepth : 4\n",
      "Area Under ROC Curve = 0.8194327154774146\n",
      "Training random forest numTrees : 10, impurity : entropy, maxBins: 24, maxDepth : 6\n",
      "Area Under ROC Curve = 0.865723147290196\n",
      "Training random forest numTrees : 10, impurity : entropy, maxBins: 24, maxDepth : 8\n",
      "Area Under ROC Curve = 0.865717282806681\n",
      "Training random forest numTrees : 10, impurity : entropy, maxBins: 28, maxDepth : 4\n",
      "Area Under ROC Curve = 0.8101793207016702\n",
      "Training random forest numTrees : 10, impurity : entropy, maxBins: 28, maxDepth : 6\n",
      "Area Under ROC Curve = 0.851834258401307\n",
      "Training random forest numTrees : 10, impurity : entropy, maxBins: 28, maxDepth : 8\n",
      "Area Under ROC Curve = 0.8564638880309366\n",
      "Training random forest numTrees : 10, impurity : entropy, maxBins: 32, maxDepth : 4\n",
      "Area Under ROC Curve = 0.8101793207016702\n",
      "Training random forest numTrees : 10, impurity : entropy, maxBins: 32, maxDepth : 6\n",
      "Area Under ROC Curve = 0.8564638880309366\n",
      "Training random forest numTrees : 10, impurity : entropy, maxBins: 32, maxDepth : 8\n",
      "Area Under ROC Curve = 0.865723147290196\n",
      "Training random forest numTrees : 10, impurity : gini, maxBins: 24, maxDepth : 4\n",
      "Area Under ROC Curve = 0.6851793207016702\n",
      "Training random forest numTrees : 10, impurity : gini, maxBins: 24, maxDepth : 6\n",
      "Area Under ROC Curve = 0.865723147290196\n",
      "Training random forest numTrees : 10, impurity : gini, maxBins: 24, maxDepth : 8\n",
      "Area Under ROC Curve = 0.8749706775824253\n",
      "Training random forest numTrees : 10, impurity : gini, maxBins: 28, maxDepth : 4\n",
      "Area Under ROC Curve = 0.6805496910720407\n",
      "Training random forest numTrees : 10, impurity : gini, maxBins: 28, maxDepth : 6\n",
      "Area Under ROC Curve = 0.8564580235474217\n",
      "Training random forest numTrees : 10, impurity : gini, maxBins: 28, maxDepth : 8\n",
      "Area Under ROC Curve = 0.8610817886935365\n",
      "Training random forest numTrees : 10, impurity : gini, maxBins: 32, maxDepth : 4\n",
      "Area Under ROC Curve = 0.6574015429238925\n",
      "Training random forest numTrees : 10, impurity : gini, maxBins: 32, maxDepth : 6\n",
      "Area Under ROC Curve = 0.8425808636255626\n",
      "Training random forest numTrees : 10, impurity : gini, maxBins: 32, maxDepth : 8\n",
      "Area Under ROC Curve = 0.8564580235474217\n",
      "Training random forest numTrees : 15, impurity : entropy, maxBins: 24, maxDepth : 4\n",
      "Area Under ROC Curve = 0.8240623451070442\n",
      "Training random forest numTrees : 15, impurity : entropy, maxBins: 24, maxDepth : 6\n",
      "Area Under ROC Curve = 0.8425808636255626\n",
      "Training random forest numTrees : 15, impurity : entropy, maxBins: 24, maxDepth : 8\n",
      "Area Under ROC Curve = 0.8518283939177922\n",
      "Training random forest numTrees : 15, impurity : entropy, maxBins: 28, maxDepth : 4\n",
      "Area Under ROC Curve = 0.8472163577387073\n",
      "Training random forest numTrees : 15, impurity : entropy, maxBins: 28, maxDepth : 6\n",
      "Area Under ROC Curve = 0.8610935176605664\n",
      "Training random forest numTrees : 15, impurity : entropy, maxBins: 28, maxDepth : 8\n",
      "Area Under ROC Curve = 0.8564697525144515\n",
      "Training random forest numTrees : 15, impurity : entropy, maxBins: 32, maxDepth : 4\n",
      "Area Under ROC Curve = 0.8055438265885256\n",
      "Training random forest numTrees : 15, impurity : entropy, maxBins: 32, maxDepth : 6\n",
      "Area Under ROC Curve = 0.8472104932551924\n",
      "Training random forest numTrees : 15, impurity : entropy, maxBins: 32, maxDepth : 8\n",
      "Area Under ROC Curve = 0.8472046287716773\n",
      "Training random forest numTrees : 15, impurity : gini, maxBins: 24, maxDepth : 4\n",
      "Area Under ROC Curve = 0.7036978392201888\n",
      "Training random forest numTrees : 15, impurity : gini, maxBins: 24, maxDepth : 6\n",
      "Area Under ROC Curve = 0.8286861102531589\n",
      "Training random forest numTrees : 15, impurity : gini, maxBins: 24, maxDepth : 8\n",
      "Area Under ROC Curve = 0.8564521590639067\n",
      "Training random forest numTrees : 15, impurity : gini, maxBins: 28, maxDepth : 4\n",
      "Area Under ROC Curve = 0.7685126540350037\n",
      "Training random forest numTrees : 15, impurity : gini, maxBins: 28, maxDepth : 6\n",
      "Area Under ROC Curve = 0.8379512339959331\n",
      "Training random forest numTrees : 15, impurity : gini, maxBins: 28, maxDepth : 8\n",
      "Area Under ROC Curve = 0.8610876531770514\n",
      "Training random forest numTrees : 15, impurity : gini, maxBins: 32, maxDepth : 4\n",
      "Area Under ROC Curve = 0.7962904318127814\n",
      "Training random forest numTrees : 15, impurity : gini, maxBins: 32, maxDepth : 6\n",
      "Area Under ROC Curve = 0.8425749991420477\n",
      "Training random forest numTrees : 15, impurity : gini, maxBins: 32, maxDepth : 8\n",
      "Area Under ROC Curve = 0.8610935176605664\n",
      "Training random forest numTrees : 20, impurity : entropy, maxBins: 24, maxDepth : 4\n",
      "Area Under ROC Curve = 0.8286978392201888\n",
      "Training random forest numTrees : 20, impurity : entropy, maxBins: 24, maxDepth : 6\n",
      "Area Under ROC Curve = 0.865723147290196\n",
      "Training random forest numTrees : 20, impurity : entropy, maxBins: 24, maxDepth : 8\n",
      "Area Under ROC Curve = 0.865717282806681\n",
      "Training random forest numTrees : 20, impurity : entropy, maxBins: 28, maxDepth : 4\n",
      "Area Under ROC Curve = 0.8194327154774146\n",
      "Training random forest numTrees : 20, impurity : entropy, maxBins: 28, maxDepth : 6\n",
      "Area Under ROC Curve = 0.8657290117737108\n",
      "Training random forest numTrees : 20, impurity : entropy, maxBins: 28, maxDepth : 8\n",
      "Area Under ROC Curve = 0.865723147290196\n",
      "Training random forest numTrees : 20, impurity : entropy, maxBins: 32, maxDepth : 4\n",
      "Area Under ROC Curve = 0.8333216043663034\n",
      "Training random forest numTrees : 20, impurity : entropy, maxBins: 32, maxDepth : 6\n",
      "Area Under ROC Curve = 0.8564638880309366\n",
      "Training random forest numTrees : 20, impurity : entropy, maxBins: 32, maxDepth : 8\n",
      "Area Under ROC Curve = 0.8564697525144515\n",
      "Training random forest numTrees : 20, impurity : gini, maxBins: 24, maxDepth : 4\n",
      "Area Under ROC Curve = 0.8194327154774146\n",
      "Training random forest numTrees : 20, impurity : gini, maxBins: 24, maxDepth : 6\n",
      "Area Under ROC Curve = 0.851834258401307\n",
      "Training random forest numTrees : 20, impurity : gini, maxBins: 24, maxDepth : 8\n",
      "Area Under ROC Curve = 0.8564580235474217\n",
      "Training random forest numTrees : 20, impurity : gini, maxBins: 28, maxDepth : 4\n",
      "Area Under ROC Curve = 0.8148030858477849\n",
      "Training random forest numTrees : 20, impurity : gini, maxBins: 28, maxDepth : 6\n",
      "Area Under ROC Curve = 0.8564580235474217\n",
      "Training random forest numTrees : 20, impurity : gini, maxBins: 28, maxDepth : 8\n",
      "Area Under ROC Curve = 0.865717282806681\n",
      "Training random forest numTrees : 20, impurity : gini, maxBins: 32, maxDepth : 4\n",
      "Area Under ROC Curve = 0.8055438265885256\n",
      "Training random forest numTrees : 20, impurity : gini, maxBins: 32, maxDepth : 6\n",
      "Area Under ROC Curve = 0.8472104932551924\n",
      "Training random forest numTrees : 20, impurity : gini, maxBins: 32, maxDepth : 8\n",
      "Area Under ROC Curve = 0.8610935176605664\n",
      "((10,gini,24,8),RandomForestClassificationModel (uid=rfc_35551cb245ea) with 10 trees,0.8749706775824253)\n",
      "((20,entropy,28,6),RandomForestClassificationModel (uid=rfc_5cd72db02b58) with 20 trees,0.8657290117737108)\n",
      "((10,entropy,24,6),RandomForestClassificationModel (uid=rfc_f4b30bba8a56) with 10 trees,0.865723147290196)\n",
      "((10,entropy,32,8),RandomForestClassificationModel (uid=rfc_215b966498c7) with 10 trees,0.865723147290196)\n",
      "((10,gini,24,6),RandomForestClassificationModel (uid=rfc_29c71eff465b) with 10 trees,0.865723147290196)\n",
      "rfModel: Unit = ()\n"
     ]
    }
   ],
   "source": [
    "val rfModel = {\n",
    "    val rfGridSearch = for (\n",
    "    rfNumTrees <- Array(10, 15, 20);\n",
    "    rfImpurity <- Array(\"entropy\",\"gini\");\n",
    "    rfMaxBins <- Array(24, 28, 32);\n",
    "    rfmaxDepth <- Array(4, 6, 8)) \n",
    "    yield {\n",
    "   println(s\"Training random forest numTrees : $rfNumTrees, impurity : $rfImpurity, maxBins: $rfMaxBins, maxDepth : $rfmaxDepth\")     \n",
    "   val rfModel = new RandomForestClassifier().setLabelCol(\"label\").setFeaturesCol(\"features\").setNumTrees(rfNumTrees).setImpurity(rfImpurity).setMaxDepth(rfmaxDepth).setSeed(42).setMaxBins(rfMaxBins).fit(trainingData)\n",
    "   val predictionsRF = rfModel.transform(validationData)      \n",
    "   val rfAUC = new BinaryClassificationEvaluator().setRawPredictionCol(\"prediction\").setLabelCol(\"label\").setMetricName(\"areaUnderROC\").evaluate(predictionsRF)  \n",
    "   println(\"Area Under ROC Curve = \" + rfAUC)\n",
    "        ((rfNumTrees, rfImpurity, rfMaxBins, rfmaxDepth), rfModel, rfAUC)\n",
    "    }\n",
    "    \n",
    "    println(rfGridSearch.sortBy(-_._3).take(5).mkString(\"\\n\"))\n",
    "        val BestModel = rfGridSearch.sortBy(-_._3).head._2\n",
    "}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: Long = 6012717937604939\n",
      "gbt: org.apache.spark.ml.classification.GBTClassifier = gbtc_85c037d429cd\n"
     ]
    }
   ],
   "source": [
    "//Gradient-boosted tree classifier\n",
    "// Train a GBT model.\n",
    "//setImpurity(\"entropy\") \n",
    "val t = System.nanoTime\n",
    "val gbt = new GBTClassifier().setLabelCol(\"label\").setFeaturesCol(\"features\").setMaxIter(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelGBT: org.apache.spark.ml.classification.GBTClassificationModel = GBTClassificationModel (uid=gbtc_85c037d429cd) with 10 trees\n",
      "durationtrain: Double = 15.953715621\n",
      "\n",
      "initial model training finished.\n",
      "Training process takes 15.953715621 secs\n"
     ]
    }
   ],
   "source": [
    "val modelGBT = gbt.fit(trainingData)\n",
    "val durationtrain = (System.nanoTime - t) / 1e9d\n",
    "println(\"\\ninitial model training finished.\")\n",
    "println(s\"Training process takes $durationtrain secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: Long = 6012736194945244\n",
      "predictionsGBT: org.apache.spark.sql.DataFrame = [V1: double, V2: double ... 35 more fields]\n",
      "durationprediction: Double = 0.264481375\n",
      "\n",
      "initial model training finished.\n",
      "Training process takes 0.264481375 secs\n",
      "res21: predictionsGBT.type = [V1: double, V2: double ... 35 more fields]\n",
      "+----------+-----+\n",
      "|prediction|label|\n",
      "+----------+-----+\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val s = System.nanoTime\n",
    "val predictionsGBT = modelGBT.transform(validationData)\n",
    "val durationprediction = (System.nanoTime - s) / 1e9d\n",
    "println(\"\\ninitial model training finished.\")\n",
    "println(s\"Training process takes $durationprediction secs\")\n",
    "predictionsGBT.cache()\n",
    "//val predictionsAndLabel: RDD[Row] = df.rdd= predictionsGBT.select(\"prediction\", \"label\")\n",
    "predictionsGBT.select(\"prediction\", \"label\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified test set :\n",
      "+-----+-----+\n",
      "|Class|count|\n",
      "+-----+-----+\n",
      "|  0.0|85259|\n",
      "|  1.0|  108|\n",
      "+-----+-----+\n",
      "\n",
      "Prediction :\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       0.0|85285|\n",
      "|       1.0|   82|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(s\"Classified test set :\")\n",
    "validationData.groupBy(\"Class\").count().show()\n",
    "println(s\"Prediction :\")\n",
    "predictionsGBT.groupBy(\"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "+----------+-----+-----+\n",
      "|prediction|label|count|\n",
      "+----------+-----+-----+\n",
      "|       0.0|  0.0|85248|\n",
      "|       1.0|  0.0|   11|\n",
      "|       0.0|  1.0|   37|\n",
      "|       1.0|  1.0|   71|\n",
      "+----------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(s\"Matrice de confusion :\")\n",
    "predictionsGBT.select(\"prediction\", \"label\").groupBy(\"prediction\", \"label\").count().orderBy(\"label\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluator1: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_50fcba2ce0b7\n",
      "evaluator2: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_1087a3f176d5\n",
      "evaluator3: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_e804f4e79b36\n",
      "evaluator4: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_50d8a0d2a048\n",
      "areaUnderROC: org.apache.spark.ml.evaluation.BinaryClassificationEvaluator = binEval_d7131bcadcb0\n",
      "accuracy: Double = 0.9994377218363067\n",
      "Area Under ROC Curve = 0.8286391943850394\n",
      "Accuracy = 0.9994377218363067\n",
      "Precision = 0.9993969973754311\n",
      "Recall = 0.9994377218363067\n",
      "F1 = 0.9993992930330633\n",
      "Test Error = 5.622781636932528E-4\n"
     ]
    }
   ],
   "source": [
    "val evaluator1 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"accuracy\")\n",
    "val evaluator2 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"weightedPrecision\")\n",
    "val evaluator3 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"weightedRecall\")\n",
    "val evaluator4 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"f1\")\n",
    "val areaUnderROC = new BinaryClassificationEvaluator().setRawPredictionCol(\"prediction\").setLabelCol(\"label\").setMetricName(\"areaUnderROC\")\n",
    "val accuracy = evaluator1.evaluate(predictionsGBT)\n",
    "println(\"Area Under ROC Curve = \" + areaUnderROC.evaluate(predictionsGBT))\n",
    "println(\"Accuracy = \" + evaluator1.evaluate(predictionsGBT))\n",
    "println(\"Precision = \" + evaluator2.evaluate(predictionsGBT))\n",
    "println(\"Recall = \" + evaluator3.evaluate(predictionsGBT))\n",
    "println(\"F1 = \" + evaluator4.evaluate(predictionsGBT))\n",
    "println(\"Test Error = \" + (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "//val metrics = new BinaryClassificationMetrics(predictionsAndLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf: org.apache.spark.ml.classification.RandomForestClassifier = rfc_de6ee969327a\n",
      "t: Long = 629651203469028\n"
     ]
    }
   ],
   "source": [
    "// Random forest classifier\n",
    "// Train a RandomForest model.\n",
    "val rf = new RandomForestClassifier().setLabelCol(\"label\").setFeaturesCol(\"features\").setNumTrees(10)\n",
    "val t = System.nanoTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelRF: org.apache.spark.ml.classification.RandomForestClassificationModel = RandomForestClassificationModel (uid=rfc_de6ee969327a) with 10 trees\n",
      "durationtrain: Double = 3.238496364\n",
      "\n",
      "initial model training finished.\n",
      "Training process takes 3.238496364 secs\n"
     ]
    }
   ],
   "source": [
    "val modelRF = rf.fit(trainingData)\n",
    "val durationtrain = (System.nanoTime - t) / 1e9d\n",
    "println(\"\\ninitial model training finished.\")\n",
    "println(s\"Training process takes $durationtrain secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: Long = 629654954133309\n",
      "predictionsRF: org.apache.spark.sql.DataFrame = [V1: double, V2: double ... 35 more fields]\n",
      "durationprediction: Double = 0.23815253\n",
      "\n",
      "initial model training finished.\n",
      "Training process takes 0.23815253 secs\n",
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       0.0|  0.0|[0.84071812067749...|\n",
      "|       0.0|  0.0|[0.83224682802076...|\n",
      "|       0.0|  0.0|[0.84713202953547...|\n",
      "|       0.0|  0.0|[0.81014624583389...|\n",
      "|       0.0|  0.0|[0.80346968413767...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val s = System.nanoTime\n",
    "val predictionsRF = modelRF.transform(validationData)\n",
    "val durationprediction = (System.nanoTime - s) / 1e9d\n",
    "println(\"\\ninitial model training finished.\")\n",
    "println(s\"Training process takes $durationprediction secs\")\n",
    "predictionsRF.select(\"prediction\", \"label\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified test set :\n",
      "+-----+-----+\n",
      "|Class|count|\n",
      "+-----+-----+\n",
      "|  0.0|85259|\n",
      "|  1.0|  108|\n",
      "+-----+-----+\n",
      "\n",
      "Prediction :\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       0.0|85289|\n",
      "|       1.0|   78|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(s\"Classified test set :\")\n",
    "validationData.groupBy(\"Class\").count().show()\n",
    "println(s\"Prediction :\")\n",
    "predictionsRF.groupBy(\"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "+----------+-----+-----+\n",
      "|prediction|label|count|\n",
      "+----------+-----+-----+\n",
      "|       0.0|  0.0|85258|\n",
      "|       1.0|  0.0|    1|\n",
      "|       0.0|  1.0|   31|\n",
      "|       1.0|  1.0|   77|\n",
      "+----------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(s\"Matrice de confusion :\")\n",
    "predictionsRF.select(\"prediction\", \"label\").groupBy(\"prediction\", \"label\").count().orderBy(\"label\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluator1: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_83e0648ec089\n",
      "evaluator2: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_18e451b60167\n",
      "evaluator3: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_6dccc8d16102\n",
      "evaluator4: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_f9acdddfab63\n",
      "areaUnderROC: org.apache.spark.ml.evaluation.BinaryClassificationEvaluator = binEval_9f0c1ce0279a\n",
      "accuracy: Double = 0.9996251478908712\n",
      "Area Under ROC Curve = 0.8564756169979665\n",
      "Accuracy = 0.9996251478908712\n",
      "Precision = 0.9996207701889245\n",
      "Recall = 0.9996251478908712\n",
      "F1 = 0.9995949508509803\n",
      "Test Error = 3.748521091287982E-4\n"
     ]
    }
   ],
   "source": [
    "val evaluator1 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"accuracy\")\n",
    "val evaluator2 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"weightedPrecision\")\n",
    "val evaluator3 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"weightedRecall\")\n",
    "val evaluator4 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"f1\")\n",
    "val areaUnderROC = new BinaryClassificationEvaluator().setRawPredictionCol(\"prediction\").setLabelCol(\"label\").setMetricName(\"areaUnderROC\")\n",
    "val accuracy = evaluator1.evaluate(predictionsRF)\n",
    "println(\"Area Under ROC Curve = \" + areaUnderROC.evaluate(predictionsRF))\n",
    "println(\"Accuracy = \" + evaluator1.evaluate(predictionsRF))\n",
    "println(\"Precision = \" + evaluator2.evaluate(predictionsRF))\n",
    "println(\"Recall = \" + evaluator3.evaluate(predictionsRF))\n",
    "println(\"F1 = \" + evaluator4.evaluate(predictionsRF))\n",
    "println(\"Test Error = \" + (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt: org.apache.spark.ml.classification.DecisionTreeClassifier = dtc_b140cd877ae3\n",
      "t: Long = 629665084108735\n"
     ]
    }
   ],
   "source": [
    "// Decision Tree classifier\n",
    "// Train a DecisionTree model.\n",
    "val dt = new DecisionTreeClassifier().setLabelCol(\"label\").setFeaturesCol(\"features\")\n",
    "val t = System.nanoTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelDT: org.apache.spark.ml.classification.DecisionTreeClassificationModel = DecisionTreeClassificationModel (uid=dtc_b140cd877ae3) of depth 5 with 31 nodes\n",
      "durationtrain: Double = 2.146376681\n",
      "\n",
      "initial model training finished.\n",
      "Training process takes 2.146376681 secs\n"
     ]
    }
   ],
   "source": [
    "val modelDT = dt.fit(trainingData)\n",
    "val durationtrain = (System.nanoTime - t) / 1e9d\n",
    "println(\"\\ninitial model training finished.\")\n",
    "println(s\"Training process takes $durationtrain secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: Long = 629667975336988\n",
      "predictionsDT: org.apache.spark.sql.DataFrame = [V1: double, V2: double ... 35 more fields]\n",
      "durationprediction: Double = 0.227669649\n",
      "\n",
      "initial model training finished.\n",
      "Training process takes 0.227669649 secs\n",
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       0.0|  0.0|[0.84071812067749...|\n",
      "|       0.0|  0.0|[0.83224682802076...|\n",
      "|       0.0|  0.0|[0.84713202953547...|\n",
      "|       0.0|  0.0|[0.81014624583389...|\n",
      "|       0.0|  0.0|[0.80346968413767...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val s = System.nanoTime\n",
    "val predictionsDT = modelDT.transform(validationData)\n",
    "val durationprediction = (System.nanoTime - s) / 1e9d\n",
    "println(\"\\ninitial model training finished.\")\n",
    "println(s\"Training process takes $durationprediction secs\")\n",
    "predictionsDT.select(\"prediction\", \"label\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified test set :\n",
      "+-----+-----+\n",
      "|Class|count|\n",
      "+-----+-----+\n",
      "|  0.0|85259|\n",
      "|  1.0|  108|\n",
      "+-----+-----+\n",
      "\n",
      "Prediction :\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       0.0|85286|\n",
      "|       1.0|   81|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(s\"Classified test set :\")\n",
    "validationData.groupBy(\"Class\").count().show()\n",
    "println(s\"Prediction :\")\n",
    "predictionsDT.groupBy(\"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "+----------+-----+-----+\n",
      "|prediction|label|count|\n",
      "+----------+-----+-----+\n",
      "|       0.0|  0.0|85254|\n",
      "|       1.0|  0.0|    5|\n",
      "|       0.0|  1.0|   32|\n",
      "|       1.0|  1.0|   76|\n",
      "+----------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(s\"Matrice de confusion :\")\n",
    "predictionsDT.select(\"prediction\", \"label\").groupBy(\"prediction\", \"label\").count().orderBy(\"label\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluator1: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_3e4708f1a14e\n",
      "evaluator2: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_54388aedc73e\n",
      "evaluator3: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_2b4679a688cd\n",
      "evaluator4: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_5787a212a6d1\n",
      "areaUnderROC: org.apache.spark.ml.evaluation.BinaryClassificationEvaluator = binEval_b55bae4f9286\n",
      "accuracy: Double = 0.9995665772488198\n",
      "Area Under ROC Curve = 0.851822529434277\n",
      "Accuracy = 0.9995665772488198\n",
      "Precision = 0.999547172372845\n",
      "Recall = 0.9995665772488198\n",
      "F1 = 0.9995356527897536\n",
      "Test Error = 4.3342275118019025E-4\n"
     ]
    }
   ],
   "source": [
    "val evaluator1 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"accuracy\")\n",
    "val evaluator2 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"weightedPrecision\")\n",
    "val evaluator3 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"weightedRecall\")\n",
    "val evaluator4 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"f1\")\n",
    "val areaUnderROC = new BinaryClassificationEvaluator().setRawPredictionCol(\"prediction\").setLabelCol(\"label\").setMetricName(\"areaUnderROC\")\n",
    "val accuracy = evaluator1.evaluate(predictionsDT)\n",
    "println(\"Area Under ROC Curve = \" + areaUnderROC.evaluate(predictionsDT))\n",
    "println(\"Accuracy = \" + evaluator1.evaluate(predictionsDT))\n",
    "println(\"Precision = \" + evaluator2.evaluate(predictionsDT))\n",
    "println(\"Recall = \" + evaluator3.evaluate(predictionsDT))\n",
    "println(\"F1 = \" + evaluator4.evaluate(predictionsDT))\n",
    "println(\"Test Error = \" + (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "/* val trainingData1 = trainingData.withColumn(\"label\", when(col(\"label\") === 0, -1)\n",
    "                                   .otherwise(col(\"label\"))\n",
    "                           );\n",
    "val validationData1 = validationData.withColumn(\"label\", when(col(\"label\") === 0, -1)\n",
    "                                   .otherwise(col(\"label\"))\n",
    "                           );*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm: org.apache.spark.ml.classification.LinearSVC = linearsvc_d3980dafb2e7\n",
      "t: Long = 629676769761255\n"
     ]
    }
   ],
   "source": [
    "// SVM classifier\n",
    "// Train a SVM model.\n",
    "val svm = new LinearSVC().setLabelCol(\"label\").setFeaturesCol(\"features\").setMaxIter(100).setRegParam(0.1) \n",
    "val t = System.nanoTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelSVM: org.apache.spark.ml.classification.LinearSVCModel = linearsvc_d3980dafb2e7\n",
      "durationtrain: Double = 61.191874208\n",
      "\n",
      "initial model training finished.\n",
      "Training process takes 61.191874208 secs\n"
     ]
    }
   ],
   "source": [
    "val modelSVM = svm.fit(trainingData)\n",
    "val durationtrain = (System.nanoTime - t) / 1e9d\n",
    "println(\"\\ninitial model training finished.\")\n",
    "println(s\"Training process takes $durationtrain secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: Long = 629740594975966\n",
      "predictionsSVM: org.apache.spark.sql.DataFrame = [V1: double, V2: double ... 34 more fields]\n",
      "durationprediction: Double = 0.209021799\n",
      "\n",
      "initial model training finished.\n",
      "Training process takes 0.209021799 secs\n",
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       0.0|  0.0|[0.84071812067749...|\n",
      "|       0.0|  0.0|[0.83224682802076...|\n",
      "|       0.0|  0.0|[0.84713202953547...|\n",
      "|       0.0|  0.0|[0.81014624583389...|\n",
      "|       0.0|  0.0|[0.80346968413767...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val s = System.nanoTime\n",
    "val predictionsSVM = modelSVM.transform(validationData)\n",
    "val durationprediction = (System.nanoTime - s) / 1e9d\n",
    "println(\"\\ninitial model training finished.\")\n",
    "println(s\"Training process takes $durationprediction secs\")\n",
    "predictionsSVM.select(\"prediction\", \"label\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified test set :\n",
      "+-----+-----+\n",
      "|Class|count|\n",
      "+-----+-----+\n",
      "|  0.0|85259|\n",
      "|  1.0|  108|\n",
      "+-----+-----+\n",
      "\n",
      "Prediction :\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       0.0|85367|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(s\"Classified test set :\")\n",
    "validationData.groupBy(\"Class\").count().show()\n",
    "println(s\"Prediction :\")\n",
    "predictionsSVM.groupBy(\"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "+----------+-----+-----+\n",
      "|prediction|label|count|\n",
      "+----------+-----+-----+\n",
      "|       0.0|  0.0|85259|\n",
      "|       0.0|  1.0|  108|\n",
      "+----------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(s\"Matrice de confusion :\")\n",
    "predictionsSVM.select(\"prediction\", \"label\").groupBy(\"prediction\", \"label\").count().orderBy(\"label\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluator1: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_816cee599cf2\n",
      "evaluator2: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_59cf454254df\n",
      "evaluator3: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_7488c30cc813\n",
      "evaluator4: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_be1855853843\n",
      "areaUnderROC: org.apache.spark.ml.evaluation.BinaryClassificationEvaluator = binEval_4384a712406c\n",
      "accuracy: Double = 0.9987348741316903\n",
      "Area Under ROC Curve = 0.5\n",
      "Accuracy = 0.9987348741316903\n",
      "Precision = 0.9974713488068432\n",
      "Recall = 0.9987348741316903\n",
      "F1 = 0.9981027115866723\n",
      "Test Error = 0.0012651258683097355\n"
     ]
    }
   ],
   "source": [
    "val evaluator1 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"accuracy\")\n",
    "val evaluator2 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"weightedPrecision\")\n",
    "val evaluator3 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"weightedRecall\")\n",
    "val evaluator4 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"f1\")\n",
    "val areaUnderROC = new BinaryClassificationEvaluator().setRawPredictionCol(\"prediction\").setLabelCol(\"label\").setMetricName(\"areaUnderROC\")\n",
    "val accuracy = evaluator1.evaluate(predictionsSVM)\n",
    "println(\"Area Under ROC Curve = \" + areaUnderROC.evaluate(predictionsSVM))\n",
    "println(\"Accuracy = \" + evaluator1.evaluate(predictionsSVM))\n",
    "println(\"Precision = \" + evaluator2.evaluate(predictionsSVM))\n",
    "println(\"Recall = \" + evaluator3.evaluate(predictionsSVM))\n",
    "println(\"F1 = \" + evaluator4.evaluate(predictionsSVM))\n",
    "println(\"Test Error = \" + (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: org.apache.spark.ml.classification.LogisticRegression = logreg_0bcb939909b1\n",
      "t: Long = 629748255603035\n"
     ]
    }
   ],
   "source": [
    "// Logistic Regression classifier\n",
    "val lr = new LogisticRegression().setLabelCol(\"label\").setFeaturesCol(\"features\").setMaxIter(10).setTol(1E-6).setFitIntercept(true).setRegParam(0.3).setElasticNetParam(0.8)\n",
    "val t = System.nanoTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modellr: org.apache.spark.ml.classification.LogisticRegressionModel = LogisticRegressionModel: uid = logreg_0bcb939909b1, numClasses = 2, numFeatures = 11\n",
      "durationtrain: Double = 1.465245704\n",
      "\n",
      "initial model training finished.\n",
      "Training process takes 1.465245704 secs\n"
     ]
    }
   ],
   "source": [
    "// train the multiclass model.\n",
    "//val Modelovr = ovr.fit(trainingData)\n",
    "val Modellr = lr.fit(trainingData)\n",
    "val durationtrain = (System.nanoTime - t) / 1e9d\n",
    "println(\"\\ninitial model training finished.\")\n",
    "println(s\"Training process takes $durationtrain secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: Long = 629750147059268\n",
      "predictionsLR: org.apache.spark.sql.DataFrame = [V1: double, V2: double ... 35 more fields]\n",
      "durationprediction: Double = 0.200476376\n",
      "\n",
      "initial model training finished.\n",
      "Training process takes 0.200476376 secs\n",
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       0.0|  0.0|[0.84071812067749...|\n",
      "|       0.0|  0.0|[0.83224682802076...|\n",
      "|       0.0|  0.0|[0.84713202953547...|\n",
      "|       0.0|  0.0|[0.81014624583389...|\n",
      "|       0.0|  0.0|[0.80346968413767...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val s = System.nanoTime\n",
    "val predictionsLR = Modellr.transform(validationData)\n",
    "val durationprediction = (System.nanoTime - s) / 1e9d\n",
    "println(\"\\ninitial model training finished.\")\n",
    "println(s\"Training process takes $durationprediction secs\")\n",
    "predictionsLR.select(\"prediction\", \"label\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified test set :\n",
      "+-----+-----+\n",
      "|Class|count|\n",
      "+-----+-----+\n",
      "|  0.0|85259|\n",
      "|  1.0|  108|\n",
      "+-----+-----+\n",
      "\n",
      "Prediction :\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       0.0|85367|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(s\"Classified test set :\")\n",
    "validationData.groupBy(\"Class\").count().show()\n",
    "println(s\"Prediction :\")\n",
    "predictionsLR.groupBy(\"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "+----------+-----+-----+\n",
      "|prediction|label|count|\n",
      "+----------+-----+-----+\n",
      "|       0.0|  0.0|85259|\n",
      "|       0.0|  1.0|  108|\n",
      "+----------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(s\"Matrice de confusion :\")\n",
    "predictionsLR.select(\"prediction\", \"label\").groupBy(\"prediction\", \"label\").count().orderBy(\"label\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluator1: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_fcb51b0447a2\n",
      "evaluator2: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_cda682de502a\n",
      "evaluator3: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_361d3df26b97\n",
      "evaluator4: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_da36650086fd\n",
      "areaUnderROC: org.apache.spark.ml.evaluation.BinaryClassificationEvaluator = binEval_60aec12f69ed\n",
      "accuracy: Double = 0.9987348741316903\n",
      "Area Under ROC Curve = 0.5\n",
      "Accuracy = 0.9987348741316903\n",
      "Precision = 0.9974713488068432\n",
      "Recall = 0.9987348741316903\n",
      "F1 = 0.9981027115866723\n",
      "Test Error = 0.0012651258683097355\n"
     ]
    }
   ],
   "source": [
    "val evaluator1 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"accuracy\")\n",
    "val evaluator2 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"weightedPrecision\")\n",
    "val evaluator3 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"weightedRecall\")\n",
    "val evaluator4 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"f1\")\n",
    "val areaUnderROC = new BinaryClassificationEvaluator().setRawPredictionCol(\"prediction\").setLabelCol(\"label\").setMetricName(\"areaUnderROC\")\n",
    "val accuracy = evaluator1.evaluate(predictionsLR)\n",
    "println(\"Area Under ROC Curve = \" + areaUnderROC.evaluate(predictionsLR))\n",
    "println(\"Accuracy = \" + evaluator1.evaluate(predictionsLR))\n",
    "println(\"Precision = \" + evaluator2.evaluate(predictionsLR))\n",
    "println(\"Recall = \" + evaluator3.evaluate(predictionsLR))\n",
    "println(\"F1 = \" + evaluator4.evaluate(predictionsLR))\n",
    "println(\"Test Error = \" + (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb: org.apache.spark.ml.classification.NaiveBayes = nb_5613a1322861\n",
      "t: Long = 629757756504823\n"
     ]
    }
   ],
   "source": [
    "// Naive Bayes classifier\n",
    "// Train a NaiveBayes model.\n",
    "val nb = new NaiveBayes().setLabelCol(\"label\").setFeaturesCol(\"features\").setSmoothing(1.0)\n",
    "val t = System.nanoTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "/*val scaler = new MinMaxScaler().setInputCol(\"features\").setOutputCol(\"featuresScaled\")\n",
    "val pipeline = new Pipeline().setStages(Array(scaler))\n",
    "val pipelineModel1 = pipeline.fit(trainingData)\n",
    "val pipelineModel2 = pipeline.fit(trainingData)\n",
    "val datatrain = pipelineModel1.transform(trainingData)\n",
    "val datatest = pipelineModel2.transform(validationData)*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelNB: org.apache.spark.ml.classification.NaiveBayesModel = NaiveBayesModel (uid=nb_5613a1322861) with 2 classes\n",
      "durationtrain: Double = 1.381058102\n",
      "\n",
      "initial model training finished.\n",
      "Training process takes 1.381058102 secs\n"
     ]
    }
   ],
   "source": [
    "val modelNB = nb.fit(trainingData)\n",
    "val durationtrain = (System.nanoTime - t) / 1e9d\n",
    "println(\"\\ninitial model training finished.\")\n",
    "println(s\"Training process takes $durationtrain secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: Long = 629759887515209\n",
      "predictionsNB: org.apache.spark.sql.DataFrame = [V1: double, V2: double ... 35 more fields]\n",
      "durationprediction: Double = 0.212813275\n",
      "\n",
      "initial model training finished.\n",
      "Training process takes 0.212813275 secs\n",
      "+----------+-----+\n",
      "|prediction|label|\n",
      "+----------+-----+\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val s = System.nanoTime\n",
    "val predictionsNB = modelNB.transform(validationData)\n",
    "val durationprediction = (System.nanoTime - s) / 1e9d\n",
    "println(\"\\ninitial model training finished.\")\n",
    "println(s\"Training process takes $durationprediction secs\")\n",
    "predictionsNB.select(\"prediction\", \"label\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified test set :\n",
      "+-----+-----+\n",
      "|Class|count|\n",
      "+-----+-----+\n",
      "|  0.0|85259|\n",
      "|  1.0|  108|\n",
      "+-----+-----+\n",
      "\n",
      "Prediction :\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       0.0|85367|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(s\"Classified test set :\")\n",
    "validationData.groupBy(\"Class\").count().show()\n",
    "println(s\"Prediction :\")\n",
    "predictionsNB.groupBy(\"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "+----------+-----+-----+\n",
      "|prediction|label|count|\n",
      "+----------+-----+-----+\n",
      "|       0.0|  0.0|85259|\n",
      "|       0.0|  1.0|  108|\n",
      "+----------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(s\"Matrice de confusion :\")\n",
    "predictionsNB.select(\"prediction\", \"label\").groupBy(\"prediction\", \"label\").count().orderBy(\"label\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluator1: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_9c4f9da90fde\n",
      "evaluator2: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_e571dbdcc56d\n",
      "evaluator3: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_5551412f2bef\n",
      "evaluator4: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_fc1168ed2cf6\n",
      "areaUnderROC: org.apache.spark.ml.evaluation.BinaryClassificationEvaluator = binEval_efa0db166513\n",
      "accuracy: Double = 0.9987348741316903\n",
      "Area Under ROC Curve = 0.5\n",
      "Accuracy = 0.9987348741316903\n",
      "Precision = 0.9974713488068432\n",
      "Recall = 0.9987348741316903\n",
      "F1 = 0.9981027115866723\n",
      "Test Error = 0.0012651258683097355\n"
     ]
    }
   ],
   "source": [
    "val evaluator1 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"accuracy\")\n",
    "val evaluator2 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"weightedPrecision\")\n",
    "val evaluator3 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"weightedRecall\")\n",
    "val evaluator4 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"f1\")\n",
    "val areaUnderROC = new BinaryClassificationEvaluator().setRawPredictionCol(\"prediction\").setLabelCol(\"label\").setMetricName(\"areaUnderROC\")\n",
    "val accuracy = evaluator1.evaluate(predictionsNB)\n",
    "println(\"Area Under ROC Curve = \" + areaUnderROC.evaluate(predictionsNB))\n",
    "println(\"Accuracy = \" + evaluator1.evaluate(predictionsNB))\n",
    "println(\"Precision = \" + evaluator2.evaluate(predictionsNB))\n",
    "println(\"Recall = \" + evaluator3.evaluate(predictionsNB))\n",
    "println(\"F1 = \" + evaluator4.evaluate(predictionsNB))\n",
    "println(\"Test Error = \" + (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: Long = 629767957201401\n",
      "layers: Array[Int] = Array(11, 6, 3, 2)\n",
      "mlp: org.apache.spark.ml.classification.MultilayerPerceptronClassifier = mlpc_ea0a4bdb9d92\n"
     ]
    }
   ],
   "source": [
    "// Multilayer Perceptron Classifier\n",
    "// create the trainer and set its parameters\n",
    "val t = System.nanoTime\n",
    "val layers = Array[Int] (11, 6, 3, 2)\n",
    "val mlp = new MultilayerPerceptronClassifier().setLayers(layers).setLabelCol(\"label\").setFeaturesCol(\"features\").setTol(1E-4).setBlockSize(128).setSeed(1234L).setMaxIter(25) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelMLP: org.apache.spark.ml.classification.MultilayerPerceptronClassificationModel = mlpc_ea0a4bdb9d92\n",
      "durationtrain: Double = 8.1446229\n",
      "\n",
      "initial model training finished.\n",
      "Training process takes 8.1446229 secs\n"
     ]
    }
   ],
   "source": [
    "// Train a Multilayer Perceptron model.\n",
    "val modelMLP = mlp.fit(trainingData)\n",
    "val durationtrain = (System.nanoTime - t) / 1e9d\n",
    "println(\"\\ninitial model training finished.\")\n",
    "println(s\"Training process takes $durationtrain secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: Long = 629778044698795\n",
      "predictionsMLP: org.apache.spark.sql.DataFrame = [V1: double, V2: double ... 35 more fields]\n",
      "durationprediction: Double = 0.204806983\n",
      "\n",
      "initial model training finished.\n",
      "Training process takes 0.204806983 secs\n",
      "+----------+-----+\n",
      "|prediction|label|\n",
      "+----------+-----+\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val s = System.nanoTime\n",
    "val predictionsMLP = modelMLP.transform(validationData)\n",
    "val durationprediction = (System.nanoTime - s) / 1e9d\n",
    "println(\"\\ninitial model training finished.\")\n",
    "println(s\"Training process takes $durationprediction secs\")\n",
    "predictionsMLP.select(\"prediction\",\"label\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified test set :\n",
      "+-----+-----+\n",
      "|Class|count|\n",
      "+-----+-----+\n",
      "|  0.0|85259|\n",
      "|  1.0|  108|\n",
      "+-----+-----+\n",
      "\n",
      "Prediction :\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       0.0|85272|\n",
      "|       1.0|   95|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(s\"Classified test set :\")\n",
    "validationData.groupBy(\"Class\").count().show()\n",
    "println(s\"Prediction :\")\n",
    "predictionsMLP.groupBy(\"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "+----------+-----+-----+\n",
      "|prediction|label|count|\n",
      "+----------+-----+-----+\n",
      "|       0.0|  0.0|85239|\n",
      "|       1.0|  0.0|   20|\n",
      "|       0.0|  1.0|   33|\n",
      "|       1.0|  1.0|   75|\n",
      "+----------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(s\"Matrice de confusion :\")\n",
    "predictionsMLP.select(\"prediction\", \"label\").groupBy(\"prediction\", \"label\").count().orderBy(\"label\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluator1: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_9a7804cf607b\n",
      "evaluator2: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_00eec797f0db\n",
      "evaluator3: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_9248b0207d11\n",
      "evaluator4: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_8a46816aa8a2\n",
      "areaUnderROC: org.apache.spark.ml.evaluation.BinaryClassificationEvaluator = binEval_0184048cc883\n",
      "accuracy: Double = 0.9993791511942554\n",
      "Area Under ROC Curve = 0.8471049325519234\n",
      "Accuracy = 0.9993791511942554\n",
      "Precision = 0.9993471504077043\n",
      "Recall = 0.9993791511942554\n",
      "F1 = 0.9993592954634178\n",
      "Test Error = 6.208488057446448E-4\n"
     ]
    }
   ],
   "source": [
    "val evaluator1 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"accuracy\")\n",
    "val evaluator2 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"weightedPrecision\")\n",
    "val evaluator3 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"weightedRecall\")\n",
    "val evaluator4 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"f1\")\n",
    "val areaUnderROC = new BinaryClassificationEvaluator().setRawPredictionCol(\"prediction\").setLabelCol(\"label\").setMetricName(\"areaUnderROC\")\n",
    "val accuracy = evaluator1.evaluate(predictionsMLP)\n",
    "println(\"Area Under ROC Curve = \" + areaUnderROC.evaluate(predictionsMLP))\n",
    "println(\"Accuracy = \" + evaluator1.evaluate(predictionsMLP))\n",
    "println(\"Precision = \" + evaluator2.evaluate(predictionsMLP))\n",
    "println(\"Recall = \" + evaluator3.evaluate(predictionsMLP))\n",
    "println(\"F1 = \" + evaluator4.evaluate(predictionsMLP))\n",
    "println(\"Test Error = \" + (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier: org.apache.spark.ml.classification.LogisticRegression = logreg_012c12484a81\n",
      "t: Long = 629786630362449\n"
     ]
    }
   ],
   "source": [
    "// One Vs Rest Classifier using Logistic Regression classifier\n",
    "val classifier = new LogisticRegression().setLabelCol(\"label\").setFeaturesCol(\"features\").setMaxIter(10).setTol(1E-6).setFitIntercept(true) \n",
    "val t = System.nanoTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ovr: org.apache.spark.ml.classification.OneVsRest = oneVsRest_8cd085ec9f37\n",
      "Modelovr: org.apache.spark.ml.classification.OneVsRestModel = oneVsRest_8cd085ec9f37\n",
      "durationtrain: Double = 4.573582428\n",
      "\n",
      "initial model training finished.\n",
      "Training process takes 4.573582428 secs\n"
     ]
    }
   ],
   "source": [
    "// train the multiclass model.\n",
    "val ovr = new OneVsRest().setClassifier(classifier)\n",
    "val Modelovr = ovr.fit(trainingData)\n",
    "val durationtrain = (System.nanoTime - t) / 1e9d\n",
    "println(\"\\ninitial model training finished.\")\n",
    "println(s\"Training process takes $durationtrain secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: Long = 629792600616211\n",
      "predictionsOVR: org.apache.spark.sql.DataFrame = [V1: double, V2: double ... 34 more fields]\n",
      "durationprediction: Double = 0.423795385\n",
      "\n",
      "initial model training finished.\n",
      "Training process takes 0.423795385 secs\n",
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       0.0|  0.0|[0.84071812067749...|\n",
      "|       0.0|  0.0|[0.83224682802076...|\n",
      "|       0.0|  0.0|[0.84713202953547...|\n",
      "|       0.0|  0.0|[0.81014624583389...|\n",
      "|       0.0|  0.0|[0.80346968413767...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val s = System.nanoTime\n",
    "val predictionsOVR = Modelovr.transform(validationData)\n",
    "val durationprediction = (System.nanoTime - s) / 1e9d\n",
    "println(\"\\ninitial model training finished.\")\n",
    "println(s\"Training process takes $durationprediction secs\")\n",
    "predictionsOVR.select(\"prediction\", \"label\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified test set :\n",
      "+-----+-----+\n",
      "|Class|count|\n",
      "+-----+-----+\n",
      "|  0.0|85259|\n",
      "|  1.0|  108|\n",
      "+-----+-----+\n",
      "\n",
      "Prediction :\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       0.0|85334|\n",
      "|       1.0|   33|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(s\"Classified test set :\")\n",
    "validationData.groupBy(\"Class\").count().show()\n",
    "println(s\"Prediction :\")\n",
    "predictionsOVR.groupBy(\"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "+----------+-----+-----+\n",
      "|prediction|label|count|\n",
      "+----------+-----+-----+\n",
      "|       0.0|  0.0|85259|\n",
      "|       0.0|  1.0|   75|\n",
      "|       1.0|  1.0|   33|\n",
      "+----------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(s\"Matrice de confusion :\")\n",
    "predictionsOVR.select(\"prediction\", \"label\").groupBy(\"prediction\", \"label\").count().orderBy(\"label\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluator1: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_e51eebbc1b66\n",
      "evaluator2: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_88ff04c328dd\n",
      "evaluator3: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_6c05c29c158b\n",
      "evaluator4: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_5a178875b67d\n",
      "areaUnderROC: org.apache.spark.ml.evaluation.BinaryClassificationEvaluator = binEval_ee7f9fe8f129\n",
      "areaUnderPR: org.apache.spark.ml.evaluation.BinaryClassificationEvaluator = binEval_742162e3e9ff\n",
      "accuracy: Double = 0.9991214403692293\n",
      "Area Under ROC Curve = 0.6527777777777778\n",
      "Area Under the Precision-Recall Curve = 0.6532170575931632\n",
      "Accuracy = 0.9991214403692293\n",
      "Precision = 0.9991222125347473\n",
      "Recall = 0.9991214403692293\n",
      "F1 = 0.9988879740192093\n",
      "Test Error = 8.785596307706589E-4\n"
     ]
    }
   ],
   "source": [
    "val evaluator1 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"accuracy\")\n",
    "val evaluator2 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"weightedPrecision\")\n",
    "val evaluator3 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"weightedRecall\")\n",
    "val evaluator4 = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"f1\")\n",
    "val areaUnderROC = new BinaryClassificationEvaluator().setRawPredictionCol(\"prediction\").setLabelCol(\"label\").setMetricName(\"areaUnderROC\")\n",
    "val areaUnderPR = new BinaryClassificationEvaluator().setRawPredictionCol(\"prediction\").setLabelCol(\"label\").setMetricName(\"areaUnderPR\")\n",
    "val accuracy = evaluator1.evaluate(predictionsOVR)\n",
    "println(\"Area Under ROC Curve = \" + areaUnderROC.evaluate(predictionsOVR))\n",
    "println(\"Area Under the Precision-Recall Curve = \"  + areaUnderPR.evaluate(predictionsOVR))\n",
    "println(\"Accuracy = \" + evaluator1.evaluate(predictionsOVR))\n",
    "println(\"Precision = \" + evaluator2.evaluate(predictionsOVR))\n",
    "println(\"Recall = \" + evaluator3.evaluate(predictionsOVR))\n",
    "println(\"F1 = \" + evaluator4.evaluate(predictionsOVR))\n",
    "println(\"Test Error = \" + (1.0 - accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark",
   "language": "",
   "name": "sparkkernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
